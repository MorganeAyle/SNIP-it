seml:
  executable: experiments/main.py
  name: train
  output_dir: gitignored/logs
  project_root_dir: ..
  conda_environment: gr

slurm:
  experiments_per_job: 1
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 8G          # memory
    cpus-per-task: 1  # num cores
    time: 0-01:00     # max time, D-HH:MM
    partition: ['gpu_all']
    # qos: interactive

###### BEGIN PARAMETER CONFIGURATION ######

fixed:
  arguments:
    eval_freq: 1000  # evaluate every n batches
    save_freq: 1e6  # save model every n epochs, besides before and after training
    batch_size: 512  # size of batches, for Imagenette 128
    seed: 333  # random seed
    max_training_minutes: 6120  # one hour and a 45 minutes max, process killed after n minutes (after finish of epoch)
    plot_weights_freq: 50  # plot pictures to tensorboard every n epochs
    prune_freq: 1  # if pruning during training: how long to wait before starting
    prune_delay: 0  # "if pruning during training: 't' from algorithm box, interval between pruning events, default=0
    epochs: 80
    rewind_to: 0  # rewind to this epoch if rewinding is done
    hidden_dim: None
    input_dim: None
    output_dim: None
    N: 1  # size of dataset (used for l0)
    snip_steps: 5  # 's' in algorithm box, number of pruning steps for 'rule of thumb', TODO
    pruning_rate: 0.00  # pruning rate passed to criterion at pruning event. however, most override this
    growing_rate: 0.0000  # grow back so much every epoch (for future criterions)
    pruning_limit: 0.90  # Prune until here, if structured in nodes, if unstructured in weights. most criterions use this instead of the pruning_rate
    learning_rate: 2e-3
    grad_clip: 10
    grad_noise: 0  # added gaussian noise to gradients
    l2_reg: 5e-5  # weight decay
    l1_reg: 0  # l1-norm regularisation
    lp_reg: 0  # lp regularisation with p < 1
    l0_reg: 1.0  # l0 reg lambda hyperparam
    hoyer_reg: 1.0  # hoyer reg lambda hyperparam
    beta_ema: 0.999  # l0 reg beta ema hyperparam

    loss: CrossEntropy
    optimizer: ADAM
    model: LeNet5  # ResNet not supported with structured
    data_set: MNIST
    ood_data_set: FASHION
    prune_criterion: SNIPit  # options: SNIP, SNIPit, SNIPitDuring, UnstructuredRandom, GRASP, HoyerSquare, IMP, // SNAPit, StructuredRandom, GateDecorators, EfficientConvNets, GroupHoyerSquare
    train_scheme: DefaultTrainer  # default: DefaultTrainer
    test_scheme: AdversarialEvaluation  # only supported on unstructured?
    attack: FGSM
    epsilons: [0.25]

    device: cuda
    run_name: ""

    checkpoint_name: None
    checkpoint_model: None

    disable_cuda_benchmark: 1  # speedup (disable) vs reproducibility (leave it)
    eval: 0
    disable_autoconfig: 0  # for the brave
    preload_all_data: 0  # load all data into ram memory for speedups
    tuning: 0  # splits trainset into train and validationset, omits test set

    track_weights: 0  # "keep statistics on the weights through training
    disable_masking: 1  # disable the ability to prune unstructured
    enable_rewinding: 1  # enable the ability to rewind to previous weights
    outer_layer_pruning: 1  # allow to prune outer layers (unstructured) or not (structured)
    random_shuffle_labels: 0  # run with random-label experiment from zhang et al
    l0: 0  # run with l0 criterion, might overwrite some other arguments
    hoyer_square: 0  # "run in unstructured DeephoyerSquare criterion, might overwrite some other arguments
    group_hoyer_square: 0 # run in unstructured Group-DeephoyerSquare criterion, might overwrite some other arguments

    disable_histograms: 1
    disable_saliency: 1
    disable_confusion: 1
    disable_weightplot: 1
    disable_netplot: 1
    skip_first_plot: 1

# l0:
#   fixed:
#     arguments:
#       loss: "L0CrossEntropy"
#       train_scheme: "L0Trainer"
#       prune_criterion: "EmptyCrit"
#       pruning_rate: 0.0
#       growing_rate: 0.0
#       outer_layer_pruning: True
#       disable_weightplot: False
#       disable_netplot: False
#       prune_delay: 10000000000000

# hoyer_square:
#   fixed:
#     arguments:
#       loss: "HoyerSquare"
#       prune_criterion: "HoyerSquare"

# group_hoyer_square:
#   fixed:
#     arguments:
#       loss: "GroupHoyerSquare"
#       prune_criterion: "GroupHoyerSquare"

MNIST: 
  fixed:
    arguments:
      input_dim: [1, 28, 28]
      output_dim: 10
      hidden_dim: [512]
      N: 60000

# FASHION:
#   fixed:
#     arguments:
#       input_dim: [1, 28, 28]
#       output_dim: 10
#       hidden_dim: [512]
#       N: 60000

# OMNIGLOT:
#   fixed:
#     arguments:
#       input_dim: [
#                 1,
#                 105,
#                 105
#         ]
#       output_dim: 1623
#       hidden_dim: [
#                 512
#         ]
#       N: 19456

# "CIFAR10": {
#         "input_dim": [
#                 3,
#                 32,
#                 32
#         ],
#         "output_dim": 10,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 50000
# },
# "CIFAR100": {
#         "input_dim": [
#                 3,
#                 32,
#                 32
#         ],
#         "output_dim": 100,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 50000
# },


# "TEST@HOME": {
#         "input_dim": [
#                 3,
#                 244,
#                 244
#         ],
#         "output_dim": 2,
#         "hidden_dim": [
#                 128
#         ],
#         "N": -1
# },
# "RUBBISH": {
#         "input_dim": [
#                 1,
#                 3,
#                 3
#         ],
#         "output_dim": 2,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 10000
# },
# "TINYIMAGENET": {
#         "input_dim": [
#                 3,
#                 128,
#                 128
#         ],
#         "output_dim": 20000,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 100096
# },
# "IMAGENETTE": {
#         "input_dim": [
#                 3,
#                 128,
#                 128
#         ],
#         "output_dim": 10,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 12928
# },
# "IMAGEWOOF": {
#         "input_dim": [
#                 3,
#                 128,
#                 128
#         ],
#         "output_dim": 10,
#         "hidden_dim": [
#                 512
#         ],
#         "N": 12928