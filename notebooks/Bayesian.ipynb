{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/nfs/homedirs/ayle/guided-research/SNIP-it/bayesian')\n",
    "import sys\n",
    "sys.path.append('/nfs/homedirs/ayle/guided-research/SNIP-it')\n",
    "\n",
    "from main_bayesian import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(dataset='CIFAR10', net_type='conv6', prune_criterion='SNR', pruning_limit=0.5, lower_limit=0.2, checkpoint='/nfs/homedirs/ayle/guided-research/SNIP-it/bayesian/checkpoints/CIFAR10/bayesian/model_conv6_bbb_relu_copy.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import data\n",
    "from main_bayesian import getModel\n",
    "import config_bayesian as cfg\n",
    "\n",
    "from main_bayesian import validate_model\n",
    "import metrics\n",
    "from uncertainty_estimation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA settings\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "in_data = init_dataset('CIFAR10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../gitignored/data/train_32x32.mat\n",
      "Using downloaded and verified file: ../gitignored/data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "ood_data = init_dataset('SVHN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_type = 'conv6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD STRUCTURED PRUNED MODEL\n",
    "if net_type == 'customconv6':\n",
    "    import pickle\n",
    "    with open('./checkpoints/CIFAR10/bayesian/model_conv6_bbb_relu_StructuredSNR_0.5.pt', 'rb') as f:\n",
    "         net = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/nfs/homedirs/ayle/model_conv6_0.5.pickle', 'rb') as f:\n",
    "     pre_pruned_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = getModel(net_type, 3, 10, priors=None, layer_type='bbb', activation_type='relu', pre_pruned_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./checkpoints/CIFAR10/bayesian/model_conv6_bbb_relu_SNR_0.5_after.pt'))\n",
    "net.eval()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/nfs/homedirs/ayle/mask.pickle', 'rb') as f:\n",
    "    mask = pickle.load(f)\n",
    "\n",
    "mask_keys = list(mask.keys())\n",
    "\n",
    "count = 0\n",
    "for name, module in net.named_modules():\n",
    "    if name.startswith('conv') or name.startswith('fc'):\n",
    "        module.mask = mask[mask_keys[count]]\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./checkpoints/CIFAR10/bayesian/model_conv6_bbb_relu_StructuredSNR_0.5_during.pt', 'rb') as f:\n",
    "     net = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 0.7\n",
    "all_scores = []\n",
    "for name, module in net.named_modules():\n",
    "    if name.startswith('conv') or name.startswith('fc'):\n",
    "        scores = torch.abs(module.W_mu) / torch.log1p(torch.exp(module.W_rho)) # / module.weight.sigma\n",
    "#         scores = - torch.log1p(torch.exp(module.W_rho)) \n",
    "        all_scores.append(scores.flatten())\n",
    "all_scores = torch.cat([x for x in all_scores])\n",
    "threshold, _ = torch.topk(all_scores, int(len(all_scores)*(1-sparsity)), sorted=True)\n",
    "acceptable_score = threshold[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in net.named_modules():\n",
    "    if name.startswith('conv') or name.startswith('fc'):\n",
    "        mask = (torch.abs(module.W_mu) / torch.log1p(torch.exp(module.W_rho))) > acceptable_score\n",
    "#         mask = - torch.log1p(torch.exp(module.W_rho))  > acceptable_score\n",
    "#         mask = (- module.weight.sigma) > acceptable_score\n",
    "        module.mask = mask\n",
    "        \n",
    "        print(mask.sum().float() / torch.numel(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../gitignored/data/train_32x32.mat\n",
      "Using downloaded and verified file: ../gitignored/data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "valid_size = 0.2\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "trainset, testset, inputs, outputs = data.getDataset('CIFAR10')\n",
    "train_loader, valid_loader, test_loader = data.getDataloader(\n",
    "trainset, testset, valid_size, batch_size, num_workers)\n",
    "\n",
    "ood_trainset, ood_testset, ood_inputs, ood_outputs = data.getDataset('SVHN')\n",
    "ood_train_loader, ood_valid_loader, ood_test_loader = data.getDataloader(\n",
    "ood_trainset, ood_testset, valid_size, batch_size, num_workers)\n",
    "\n",
    "criterion = metrics.ELBO(len(trainset)).to(device)\n",
    "beta_type = 0.1\n",
    "epoch = 1\n",
    "n_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ens = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031717088222503666\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_acc, max_probs = validate_model(net, criterion, valid_loader, num_ens=n_ens, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87109375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03181596131160341\n"
     ]
    }
   ],
   "source": [
    "ood_valid_loss, _, ood_max_probs = validate_model(net, criterion, ood_valid_loader, num_ens=n_ens, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as sk_metrics\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def calculate_auroc(correct, predictions):\n",
    "    fpr, tpr, thresholds = sk_metrics.roc_curve(correct, predictions)\n",
    "    auroc = sk_metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr)\n",
    "    return auroc\n",
    "\n",
    "\n",
    "def calculate_aupr(correct, predictions):\n",
    "    aupr = sk_metrics.average_precision_score(correct, predictions)\n",
    "    return aupr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8818860623848201\n",
      "0.8850588808019657\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrects = np.concatenate((np.ones_like(max_probs), np.zeros_like(ood_max_probs)))\n",
    "print(calculate_auroc(corrects, np.concatenate((max_probs, ood_max_probs))))\n",
    "print(calculate_aupr(corrects, np.concatenate((max_probs, ood_max_probs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class DS(Dataset):\n",
    "\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.mean = [0.485, 0.456, 0.406]  # avg 0.449\n",
    "        self.std = [0.229, 0.224, 0.225]  # avg 0.226\n",
    "        self.transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=self.mean, std=self.std)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = self.images[item] / 255\n",
    "        image = self.transforms(image.transpose((1, 2, 0)))\n",
    "        return image.to(torch.float32), torch.tensor(self.labels[item], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    \n",
    "ds_path = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/data/cifar10_corrupted'\n",
    "for ds_dataset_name in os.listdir(ds_path):\n",
    "    if ds_dataset_name.startswith('impulse_noise_5') or ds_dataset_name.startswith('elastic_5') or ds_dataset_name.startswith('brightness_5'):\n",
    "        npz_dataset = np.load(os.path.join(ds_path, ds_dataset_name))\n",
    "\n",
    "        ds_dataset = DS(npz_dataset[\"images\"], npz_dataset[\"labels\"])\n",
    "        ds_loader = torch.utils.data.DataLoader(\n",
    "            ds_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        ood_valid_loss, ood_acc, ood_max_probs = validate_model(net, criterion, ds_loader, num_ens=n_ens, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
    "\n",
    "        print(ds_dataset_name)\n",
    "        print(ood_acc)\n",
    "        corrects = np.concatenate((np.ones_like(max_probs), np.zeros_like(ood_max_probs)))\n",
    "        print(calculate_auroc(corrects, np.concatenate((max_probs, ood_max_probs))))\n",
    "        print(calculate_aupr(corrects, np.concatenate((max_probs, ood_max_probs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
