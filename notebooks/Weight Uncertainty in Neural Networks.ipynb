{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbQWL5WznhJS"
   },
   "source": [
    "# Bayes by Backprop\n",
    "An implementation of the algorithm described in https://arxiv.org/abs/1505.05424.  \n",
    "This notebook accompanies the article at https://www.nitarshan.com/bayes-by-backprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yNGUXrL_osEt"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "from copy import deepcopy\n",
    "\n",
    "writer = SummaryWriter()\n",
    "sns.set()\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(\"muted\")\n",
    "sns.set_color_codes(\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1528263793235,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "oGXTNl-Vt7PF",
    "outputId": "d53f7e66-2071-43f4-ac11-9589ba4846c2"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-N2EKVF_muVQ"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SMzSB6ebovaD"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "TEST_BATCH_SIZE = 5\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        './fmnist', train=True, download=True,\n",
    "        transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **LOADER_KWARGS)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        './fmnist', train=False, download=True,\n",
    "        transform=transforms.ToTensor()),\n",
    "    batch_size=TEST_BATCH_SIZE, shuffle=False, **LOADER_KWARGS)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.CIFAR10(\n",
    "#         '../gitignored/data', train=True, download=True,\n",
    "#         transform=transforms.ToTensor()),\n",
    "#     batch_size=BATCH_SIZE, shuffle=True, **LOADER_KWARGS)\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.CIFAR10(\n",
    "#         '../gitignored/data', train=False, download=True,\n",
    "#         transform=transforms.ToTensor()),\n",
    "#     batch_size=TEST_BATCH_SIZE, shuffle=False, **LOADER_KWARGS)\n",
    "\n",
    "TRAIN_SIZE = len(train_loader.dataset)\n",
    "TEST_SIZE = len(test_loader.dataset)\n",
    "NUM_BATCHES = len(train_loader)\n",
    "NUM_TEST_BATCHES = len(test_loader)\n",
    "\n",
    "CLASSES = 10\n",
    "TRAIN_EPOCHS = 20\n",
    "SAMPLES = 2\n",
    "TEST_SAMPLES = 10\n",
    "\n",
    "assert (TRAIN_SIZE % BATCH_SIZE) == 0\n",
    "assert (TEST_SIZE % TEST_BATCH_SIZE) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hkpPckMmRUR"
   },
   "source": [
    "## Modelling\n",
    "$$\\underline{\\text{Reparameterized Gaussian}}$$\n",
    "$$\\begin{aligned}\n",
    "\\theta &= (\\mu, \\rho)\\\\\n",
    "\\sigma &= \\ln{(1+e^\\rho)}\\\\\n",
    "\\mathcal{N}(x\\vert \\mu, \\sigma) &= \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\\\\n",
    "\\ln{\\mathcal{N}(x\\vert \\mu, \\sigma)} &= -\\ln{\\sqrt{2\\pi}} -\\ln{\\sigma} -\\frac{(x-\\mu)^2}{2\\sigma^2}\\\\\n",
    "P(\\mathbf{w}) &= \\prod_j{\\mathcal{N}(\\mathbf{w}_j \\vert 0, \\sigma^2)}\\\\\n",
    "\\ln{P(\\mathbf{w})} &= \\sum_j{\\ln{\\mathcal{N}(\\mathbf{w}_j \\vert 0, \\sigma^2)}}\\\\\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q9-GjqfnozFI"
   },
   "outputs": [],
   "source": [
    "class Gaussian(object):\n",
    "    def __init__(self, mu, rho):\n",
    "        super().__init__()\n",
    "        self.mu = mu\n",
    "        self.rho = rho\n",
    "        self.normal = torch.distributions.Normal(0,1)\n",
    "        self.mask = torch.ones_like(self.mu)\n",
    "    \n",
    "    @property\n",
    "    def sigma(self):\n",
    "        return torch.log1p(torch.exp(self.rho))\n",
    "    \n",
    "    def sample(self):\n",
    "        epsilon = self.normal.sample(self.rho.size()).to(DEVICE)\n",
    "        return self.mu + (self.sigma * epsilon) * self.mask.to(self.mu.device)\n",
    "    \n",
    "    def log_prob(self, input):\n",
    "        return (-math.log(math.sqrt(2 * math.pi))\n",
    "                - torch.log(self.sigma)\n",
    "                - ((input - self.mu) ** 2) / (2 * self.sigma ** 2)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bezhA1xVntod"
   },
   "source": [
    "$$\\underline{\\text{Scale Mixture Gaussian}}$$\n",
    "$$\\begin{align}\n",
    "P(\\mathbf{w}) &= \\prod_j{\\pi \\mathcal{N}(\\mathbf{w}_j \\vert 0, \\sigma_1^2) + (1-\\pi) \\mathcal{N}(\\mathbf{w}_j \\vert 0, \\sigma_2^2)}\\\\\n",
    "\\ln{P(\\mathbf{w})} &= \\sum_j{\\ln{(\\pi \\mathcal{N}(\\mathbf{w}_j \\vert 0, \\sigma_1^2) + (1-\\pi) \\mathcal{N}(\\mathbf{w}_j \\vert 0, \\sigma_2^2))}}\\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "L3wQlWNVo3S_"
   },
   "outputs": [],
   "source": [
    "class ScaleMixtureGaussian(object):\n",
    "    def __init__(self, pi, sigma1, sigma2):\n",
    "        super().__init__()\n",
    "        self.pi = pi\n",
    "        self.sigma1 = sigma1\n",
    "        self.sigma2 = sigma2\n",
    "        self.gaussian1 = torch.distributions.Normal(0,sigma1)\n",
    "        self.gaussian2 = torch.distributions.Normal(0,sigma2)\n",
    "    \n",
    "    def log_prob(self, input):\n",
    "        prob1 = torch.exp(self.gaussian1.log_prob(input))\n",
    "        prob2 = torch.exp(self.gaussian2.log_prob(input))\n",
    "        return (torch.log(self.pi * prob1 + (1-self.pi) * prob2)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwvLm9zGl3N7"
   },
   "source": [
    "$$\\pi = \\frac{1}{2}$$\n",
    "$$-\\ln{\\sigma_1} = 0$$\n",
    "$$-\\ln{\\sigma_2} = 6$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31782,
     "status": "ok",
     "timestamp": 1528263837119,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "fzTq5zWgo5p8",
    "outputId": "cc845c99-ce8d-4cbe-f79a-c0fd4ee72e63"
   },
   "outputs": [],
   "source": [
    "PI = 0.5\n",
    "SIGMA_1 = torch.cuda.FloatTensor([math.exp(-0)])\n",
    "SIGMA_2 = torch.cuda.FloatTensor([math.exp(-6)])\n",
    "\n",
    "# def visualize_scale_mixture_components():\n",
    "#     def show_lines():\n",
    "#         pass\n",
    "#     mix = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "#     normal_1 = torch.distributions.Normal(0, SIGMA_1)\n",
    "#     normal_2 = torch.distributions.Normal(0, SIGMA_2)\n",
    "#     x_points = np.linspace(-5,5,10000)\n",
    "#     d1 = np.array([torch.exp(normal_1.log_prob(float(c))) for c in x_points])\n",
    "#     d2 = np.array([torch.exp(normal_2.log_prob(float(c))) for c in x_points])\n",
    "#     d3 = np.array([torch.exp(mix.log_prob(float(c))) for c in x_points])\n",
    "#     plt.subplots(1,3,figsize=(14,4))\n",
    "#     plt.subplot(1,3,1)\n",
    "#     plt.plot(x_points,d2,color=\"g\")\n",
    "#     plt.plot(x_points,d3,color=\"r\")\n",
    "#     plt.plot(x_points,d1,color=\"b\")\n",
    "#     plt.legend([\"sigma2\", \"mix\", \"sigma1\"])\n",
    "#     plt.ylim(0,0.5)\n",
    "#     plt.subplot(1,3,2)\n",
    "#     plt.plot(x_points,d1,color=\"b\")\n",
    "#     plt.plot(x_points,d2,color=\"g\")\n",
    "#     plt.plot(x_points,d3,color=\"r\")\n",
    "#     plt.legend([\"sigma1\", \"sigma2\", \"mix\"])\n",
    "#     plt.ylim(0,160)\n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.plot(x_points,d2,color=\"g\")\n",
    "#     plt.plot(x_points,d3,color=\"r\")\n",
    "#     plt.plot(x_points,d1,color=\"b\")\n",
    "#     plt.legend([\"sigma2\", \"mix\", \"sigma1\"])\n",
    "#     plt.ylim(0,80)\n",
    "    \n",
    "# visualize_scale_mixture_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ju2J8fneo7kc"
   },
   "outputs": [],
   "source": [
    "class BayesianLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        # Weight parameters\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.2, 0.2))\n",
    "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-5,-4))\n",
    "        self.weight = Gaussian(self.weight_mu, self.weight_rho)\n",
    "        # Bias parameters\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5,-4))\n",
    "        self.bias = Gaussian(self.bias_mu, self.bias_rho)\n",
    "        # Prior distributions\n",
    "        self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "        self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "        self.log_prior = 0\n",
    "        self.log_variational_posterior = 0\n",
    "\n",
    "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
    "        if self.training or sample:\n",
    "            weight = self.weight.sample()\n",
    "            bias = self.bias.sample()\n",
    "        else:\n",
    "            weight = self.weight.mu\n",
    "            bias = self.bias.mu\n",
    "        if self.training or calculate_log_probs:\n",
    "            self.log_prior = self.weight_prior.log_prob(weight) + self.bias_prior.log_prob(bias)\n",
    "            self.log_variational_posterior = self.weight.log_prob(weight) + self.bias.log_prob(bias)\n",
    "        else:\n",
    "            self.log_prior, self.log_variational_posterior = 0, 0\n",
    "\n",
    "        return F.linear(input, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "itSuNJtYo-X7"
   },
   "outputs": [],
   "source": [
    "class BayesianNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = BayesianLinear(28*28, 1200)\n",
    "#         self.l1 = BayesianLinear(3*32*32, 1200)\n",
    "        self.l2 = BayesianLinear(1200, 1200)\n",
    "        self.l3 = BayesianLinear(1200, 10)\n",
    "    \n",
    "    def forward(self, x, sample=False):\n",
    "        x = x.view(-1, 28*28)\n",
    "#         x = x.view(-1, 3*32*32)\n",
    "        x = F.relu(self.l1(x, sample))\n",
    "        x = F.relu(self.l2(x, sample))\n",
    "        x = F.log_softmax(self.l3(x, sample), dim=1)\n",
    "        return x\n",
    "    \n",
    "    def log_prior(self):\n",
    "        return self.l1.log_prior \\\n",
    "               + self.l2.log_prior \\\n",
    "               + self.l3.log_prior\n",
    "    \n",
    "    def log_variational_posterior(self):\n",
    "        return self.l1.log_variational_posterior \\\n",
    "               + self.l2.log_variational_posterior \\\n",
    "               + self.l3.log_variational_posterior\n",
    "    \n",
    "    def sample_elbo(self, input, target, samples=SAMPLES):\n",
    "        outputs = torch.zeros(samples, BATCH_SIZE, CLASSES).to(DEVICE)\n",
    "        log_priors = torch.zeros(samples).to(DEVICE)\n",
    "        log_variational_posteriors = torch.zeros(samples).to(DEVICE)\n",
    "        for i in range(samples):\n",
    "            outputs[i] = self(input, sample=True)\n",
    "            log_priors[i] = self.log_prior()\n",
    "            log_variational_posteriors[i] = self.log_variational_posterior()\n",
    "        log_prior = log_priors.mean()\n",
    "        log_variational_posterior = log_variational_posteriors.mean()\n",
    "        negative_log_likelihood = F.nll_loss(outputs.mean(0), target, size_average=False)\n",
    "        loss = (log_variational_posterior - log_prior)/NUM_BATCHES + negative_log_likelihood\n",
    "        return loss, log_prior, log_variational_posterior, negative_log_likelihood\n",
    "\n",
    "net = BayesianNetwork().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-HLpkfPm2BI"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SJXePX9KpAu0"
   },
   "outputs": [],
   "source": [
    "def write_weight_histograms(epoch):\n",
    "    writer.add_histogram('histogram/w1_mu', net.l1.weight_mu,epoch)\n",
    "    writer.add_histogram('histogram/w1_rho', net.l1.weight_rho,epoch)\n",
    "    writer.add_histogram('histogram/w2_mu', net.l2.weight_mu,epoch)\n",
    "    writer.add_histogram('histogram/w2_rho', net.l2.weight_rho,epoch)\n",
    "    writer.add_histogram('histogram/w3_mu', net.l3.weight_mu,epoch)\n",
    "    writer.add_histogram('histogram/w3_rho', net.l3.weight_rho,epoch)\n",
    "    writer.add_histogram('histogram/b1_mu', net.l1.bias_mu,epoch)\n",
    "    writer.add_histogram('histogram/b1_rho', net.l1.bias_rho,epoch)\n",
    "    writer.add_histogram('histogram/b2_mu', net.l2.bias_mu,epoch)\n",
    "    writer.add_histogram('histogram/b2_rho', net.l2.bias_rho,epoch)\n",
    "    writer.add_histogram('histogram/b3_mu', net.l3.bias_mu,epoch)\n",
    "    writer.add_histogram('histogram/b3_rho', net.l3.bias_rho,epoch)\n",
    "\n",
    "def write_loss_scalars(epoch, batch_idx, loss, log_prior, log_variational_posterior, negative_log_likelihood):\n",
    "    writer.add_scalar('logs/loss', loss, epoch*NUM_BATCHES+batch_idx)\n",
    "    writer.add_scalar('logs/complexity_cost', log_variational_posterior-log_prior, epoch*NUM_BATCHES+batch_idx)\n",
    "    writer.add_scalar('logs/log_prior', log_prior, epoch*NUM_BATCHES+batch_idx)\n",
    "    writer.add_scalar('logs/log_variational_posterior', log_variational_posterior, epoch*NUM_BATCHES+batch_idx)\n",
    "    writer.add_scalar('logs/negative_log_likelihood', negative_log_likelihood, epoch*NUM_BATCHES+batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "q31y405kpGxt"
   },
   "outputs": [],
   "source": [
    "def train(net, optimizer, epoch):\n",
    "    net.train()\n",
    "    if epoch == 0: # write initial distributions\n",
    "        write_weight_histograms(epoch)\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        net.zero_grad()\n",
    "        loss, log_prior, log_variational_posterior, negative_log_likelihood = net.sample_elbo(data, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        write_loss_scalars(epoch, batch_idx, loss, log_prior, log_variational_posterior, negative_log_likelihood)\n",
    "    write_weight_histograms(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1090232,
     "status": "ok",
     "timestamp": 1528264929340,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "cWaZ4c93pJkm",
    "outputId": "379e274f-ac3b-406b-9d31-c1a760242f84"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters())\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    train(net, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "backup_net = deepcopy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = deepcopy(backup_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in net.named_modules():\n",
    "#     if name in ['l1', 'l2']:\n",
    "#         breakpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for name, module in net.named_modules():\n",
    "    if name in ['l1', 'l2']:\n",
    "#         scores = - module.weight.sigma\n",
    "        scores = torch.abs(module.weight.mu) / module.weight.sigma\n",
    "        all_scores.append(scores.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = torch.cat([x for x in all_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.histc(all_scores, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold, _ = torch.topk(all_scores, int(len(all_scores)*0.25), sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_score = threshold[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in net.named_modules():\n",
    "    if name in ['l1', 'l2']:\n",
    "        mask = (torch.abs(module.weight.mu) / module.weight.sigma > acceptable_score)\n",
    "#         mask = (- module.weight.sigma) > acceptable_score\n",
    "        module.weight.mu = mask * module.weight.mu\n",
    "        module.weight.mask = mask\n",
    "        \n",
    "        print(mask.sum().float() / torch.numel(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LwmjhEqlm64B"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6zoJviDmArm"
   },
   "source": [
    "### Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 198116,
     "status": "ok",
     "timestamp": 1528265127612,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "j4OzjvLHpL3o",
    "outputId": "1a8164fc-85d0-4b08-e010-33c3b7322b09"
   },
   "outputs": [],
   "source": [
    "def test_ensemble():\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    corrects = np.zeros(TEST_SAMPLES+1, dtype=int)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            outputs = torch.zeros(TEST_SAMPLES+1, TEST_BATCH_SIZE, CLASSES).to(DEVICE)\n",
    "            for i in range(TEST_SAMPLES):\n",
    "                outputs[i] = net(data, sample=True)\n",
    "            outputs[TEST_SAMPLES] = net(data, sample=False)\n",
    "            output = outputs.mean(0)\n",
    "            preds = preds = outputs.max(2, keepdim=True)[1]\n",
    "            pred = output.max(1, keepdim=True)[1] # index of max log-probability\n",
    "            corrects += preds.eq(target.view_as(pred)).sum(dim=1).squeeze().cpu().numpy()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    for index, num in enumerate(corrects):\n",
    "        if index < TEST_SAMPLES:\n",
    "            print('Component {} Accuracy: {}/{}'.format(index, num, TEST_SIZE))\n",
    "        else:\n",
    "            print('Posterior Mean Accuracy: {}/{}'.format(num, TEST_SIZE))\n",
    "    print('Ensemble Accuracy: {}/{}'.format(correct, TEST_SIZE))\n",
    "\n",
    "test_ensemble()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Xa8bwZcnO2R"
   },
   "source": [
    "### Model Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jMpmGG8unTUQ"
   },
   "source": [
    "#### In-Domain Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qwd_xrtqpsvJ"
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1528265130861,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "WhBywGVNpt9p",
    "outputId": "1528cd63-e80a-49fa-8ab9-2c46c786cc7f"
   },
   "outputs": [],
   "source": [
    "fmnist_sample = iter(test_loader).next()\n",
    "fmnist_sample[0] = fmnist_sample[0].to(DEVICE)\n",
    "print(fmnist_sample[1])\n",
    "sns.set_style(\"dark\")\n",
    "show(make_grid(fmnist_sample[0].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2293,
     "status": "ok",
     "timestamp": 1528265133412,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "PBxwd31ppwIo",
    "outputId": "4349ee1a-6102-4e84-daf5-fe7888db37e0"
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "fmnist_outputs = net(fmnist_sample[0], True).max(1, keepdim=True)[1].detach().cpu().numpy()\n",
    "for _ in range(99):\n",
    "    fmnist_outputs = np.append(fmnist_outputs, net(fmnist_sample[0], True).max(1, keepdim=True)[1].detach().cpu().numpy(), axis=1)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.subplots(5,1,figsize=(10,4))\n",
    "for i in range(5):\n",
    "    plt.subplot(5,1,i+1)\n",
    "    plt.ylim(0,100)\n",
    "    plt.xlabel(\"Categories\")\n",
    "    plt.xticks(range(10), [\"Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"])\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.yticks(range(50,101,50))\n",
    "    plt.hist(fmnist_outputs[i], np.arange(-0.5, 10, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1v7EqhO5nY52"
   },
   "source": [
    "#### Out-of-Domain Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MkgNoIeCpzVF"
   },
   "outputs": [],
   "source": [
    "mnist_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../gitignored/data', train=False, download=True, transform=transforms.ToTensor()), batch_size=5, shuffle=False)\n",
    "\n",
    "# mnist_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.SVHN('../gitignored/data', split='test', download=True, transform=transforms.ToTensor()), batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_auroc(correct, predictions):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(correct, predictions)\n",
    "    auroc = metrics.auc(fpr, tpr)\n",
    "    return auroc\n",
    "\n",
    "\n",
    "def calculate_aupr(correct, predictions):\n",
    "    aupr = metrics.average_precision_score(correct, predictions)\n",
    "    return aupr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_labels = []\n",
    "ood_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, _ in test_loader:\n",
    "        data = data.to(DEVICE)\n",
    "        out = net(data, True)\n",
    "        probs = F.softmax(out, 1)\n",
    "\n",
    "        max_probs, _  = probs.max(1)\n",
    "        max_probs = max_probs.detach().cpu().numpy()\n",
    "        ood_labels.append(np.ones_like(max_probs))\n",
    "        ood_scores.append(max_probs)\n",
    "\n",
    "    for data, _ in mnist_loader:\n",
    "        data = data.to(DEVICE)\n",
    "        out = net(data, True)\n",
    "        probs = F.softmax(out, 1)\n",
    "\n",
    "        max_probs, _  = probs.max(1)\n",
    "        max_probs = max_probs.detach().cpu().numpy()\n",
    "        ood_labels.append(np.zeros_like(max_probs))\n",
    "        ood_scores.append(max_probs)\n",
    "    \n",
    "ood_labels = np.concatenate(ood_labels)\n",
    "ood_scores = np.concatenate(ood_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_scores[10000:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_auroc(ood_labels, ood_scores))\n",
    "print(calculate_aupr(ood_labels, ood_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7348483900000001\n",
    "# 0.7189197489131008\n",
    "\n",
    "# 0.6768591982944069\n",
    "# 0.495362640026969\n",
    "\n",
    "# 0.657779435\n",
    "# 0.6424149416360756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1528265134913,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "oB1TCdv7C97a",
    "outputId": "36b7bec9-7b6a-4f8a-80ae-98180f9b65a3"
   },
   "outputs": [],
   "source": [
    "mnist_sample = iter(mnist_loader).next()\n",
    "mnist_sample[0] = mnist_sample[0].to(DEVICE)\n",
    "print(mnist_sample[1])\n",
    "sns.set_style(\"dark\")\n",
    "show(make_grid(mnist_sample[0].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2254,
     "status": "ok",
     "timestamp": 1528265137311,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "DLSygPieC-7q",
    "outputId": "5b016b5a-7256-4af6-f6f5-53487b841137"
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "mnist_outputs = net(mnist_sample[0], True).max(1, keepdim=True)[1].detach().cpu().numpy()\n",
    "for _ in range(99):\n",
    "    mnist_outputs = np.append(mnist_outputs, net(mnist_sample[0], True).max(1, keepdim=True)[1].detach().cpu().numpy(), axis=1)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.subplots(5,1,figsize=(10,4))\n",
    "for i in range(5):\n",
    "    plt.subplot(5,1,i+1)\n",
    "    plt.ylim(0,100)\n",
    "    plt.xlabel(\"Categories\")\n",
    "    plt.xticks(range(10), [\"Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"])\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.yticks(range(50,101,50))\n",
    "    plt.hist(mnist_outputs[i], np.arange(-0.5, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1528265139007,
     "user": {
      "displayName": "Nitarshan Rajkumar",
      "photoUrl": "//lh6.googleusercontent.com/-oLz5q0aJmAQ/AAAAAAAAAAI/AAAAAAAAAIY/O0-NjvATt18/s50-c-k-no/photo.jpg",
      "userId": "117587045527370134083"
     },
     "user_tz": 420
    },
    "id": "PHMriPNTDBuY",
    "outputId": "3943e78a-4f3f-4c1d-d9b8-c5f44a037ef5"
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark --updated --datename --python --machine --watermark -p torch,numpy,matplotlib,tensorboardX,torchvision,seaborn"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "bayes-by-backprop.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
