{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/nfs/homedirs/ayle/guided-research/SNIP-it/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import foolbox as fb\n",
    "from experiments.main import load_checkpoint\n",
    "from models import GeneralModel\n",
    "from models.statistics.Metrics import Metrics\n",
    "from utils.config_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.system_utils import *\n",
    "from utils.attacks_utils import get_attack\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arguments = dict({\n",
    "'eval_freq': 1000,  # evaluate every n batches\n",
    "    'save_freq': 1e6,  # save model every n epochs, besides before and after training\n",
    "    'batch_size': 512,  # size of batches, for Imagenette 128\n",
    "    'seed': 1234,  # random seed\n",
    "    'max_training_minutes': 6120 , # one hour and a 45 minutes max, process killed after n minutes (after finish of epoch)\n",
    "    'plot_weights_freq': 50, # plot pictures to tensorboard every n epochs\n",
    "    'prune_freq': 1, # if pruning during training: how long to wait before starting\n",
    "    'prune_delay': 0, # \"if pruning during training: 't' from algorithm box, interval between pruning events, default=0\n",
    "    'prune_to': 0,\n",
    "    'epochs': 0,\n",
    "    'rewind_to': 0, # rewind to this epoch if rewinding is done\n",
    "    'snip_steps': 5, # 's' in algorithm box, number of pruning steps for 'rule of thumb', TODO\n",
    "    'pruning_rate': 0.0, # pruning rate passed to criterion at pruning event. however, most override this\n",
    "    'growing_rate': 0.0000 , # grow back so much every epoch (for future criterions)\n",
    "    'pruning_limit': 0.5,  # Prune until here, if structured in nodes, if unstructured in weights. most criterions use this instead of the pruning_rate\n",
    "    'local_pruning': 0,\n",
    "    'learning_rate': 2e-3,\n",
    "    'grad_clip': 10,\n",
    "    'grad_noise': 0 , # added gaussian noise to gradients\n",
    "    'l2_reg': 5e-5 , # weight decay\n",
    "    'l1_reg': 0 , # l1-norm regularisation\n",
    "    'lp_reg': 0 , # lp regularisation with p < 1\n",
    "    'l0_reg': 1.0 , # l0 reg lambda hyperparam\n",
    "    'hoyer_reg': 0.001 , # hoyer reg lambda hyperparam\n",
    "    'beta_ema': 0.999 , # l0 reg beta ema hyperparam\n",
    "\n",
    "    'loss': 'CrossEntropy',\n",
    "    'optimizer': 'ADAM',\n",
    "    'model': 'ResNet18',  # ResNet not supported with structured\n",
    "    'data_set': 'CIFAR10',\n",
    "    'ood_data_set': 'SVHN',\n",
    "    'ood_data_set_prune': 'SVHN',\n",
    "    'prune_criterion': 'EmptyCrit',  # options: SNIP, SNIPit, SNIPitDuring, UnstructuredRandom, GRASP, HoyerSquare, IMP, // SNAPit, StructuredRandom, GateDecorators, EfficientConvNets, GroupHoyerSquare\n",
    "    'train_scheme': 'DefaultTrainer' , # default: DefaultTrainer\n",
    "    'attack': 'FGSM',\n",
    "    'epsilon': 12,\n",
    "    'eval_ood_data_sets': ['SVHN', 'CIFAR100'],\n",
    "    'eval_attacks': ['FGSM', 'L2FGSM'],\n",
    "    'eval_epsilons': [6, 12, 48],\n",
    "\n",
    "    'device': 'cuda',\n",
    "    'results_dir': \"tests\",\n",
    "\n",
    "    'checkpoint_name': None,\n",
    "    'checkpoint_model': None,\n",
    "\n",
    "    'disable_cuda_benchmark': 1 , # speedup (disable) vs reproducibility (leave it)\n",
    "    'eval': 0,\n",
    "    'disable_autoconfig': 0 , # for the brave\n",
    "    'preload_all_data': 0 , # load all data into ram memory for speedups\n",
    "    'tuning': 0 , # splits trainset into train and validationset, omits test set\n",
    "\n",
    "    'get_hooks': 0,\n",
    "    'track_weights': 0 , # \"keep statistics on the weights through training\n",
    "    'disable_masking': 1 , # disable the ability to prune unstructured\n",
    "    'enable_rewinding': 0, # enable the ability to rewind to previous weights\n",
    "    'outer_layer_pruning': 1, # allow to prune outer layers (unstructured) or not (structured)\n",
    "    'first_layer_dense': 0,\n",
    "    'random_shuffle_labels': 0  ,# run with random-label experiment from zhang et al\n",
    "    'l0': 0,  # run with l0 criterion, might overwrite some other arguments\n",
    "    'hoyer_square': 0, # \"run in unstructured DeephoyerSquare criterion, might overwrite some other arguments\n",
    "    'group_hoyer_square': 0 ,# run in unstructured Group-DeephoyerSquare criterion, might overwrite some other arguments\n",
    "\n",
    "    'disable_histograms': 0,\n",
    "    'disable_saliency': 0,\n",
    "    'disable_confusion': 0,\n",
    "    'disable_weightplot': 0,\n",
    "    'disable_netplot': 0,\n",
    "    'skip_first_plot': 0,\n",
    "    'disable_activations': 0,\n",
    "    \n",
    "#     'input_dim': [1, 28, 28],\n",
    "#       'output_dim': 10,\n",
    "#       'hidden_dim': [512],\n",
    "#       'N': 60000,\n",
    "    \n",
    "    'input_dim': [3, 32, 32],\n",
    "      'output_dim': 10,\n",
    "      'hidden_dim': [512],\n",
    "      'N': 60000\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from sacred import Experiment\n",
    "import numpy as np\n",
    "import seml\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "from models import GeneralModel\n",
    "from models.statistics.Metrics import Metrics\n",
    "from utils.config_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.system_utils import *\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from lipEstimation.lipschitz_utils import compute_module_input_sizes\n",
    "from lipEstimation.lipschitz_approximations import lipschitz_spectral_ub\n",
    "\n",
    "\n",
    "def main(\n",
    "        arguments,\n",
    "        metrics: Metrics\n",
    "):\n",
    "\n",
    "    global out\n",
    "    out = metrics.log_line\n",
    "    out(f\"starting at {get_date_stamp()}\")\n",
    "\n",
    "    # hardware\n",
    "    device = configure_device(arguments)\n",
    "\n",
    "    if arguments['disable_cuda_benchmark']:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # for reproducibility\n",
    "    configure_seeds(arguments, device)\n",
    "\n",
    "    # filter for incompatible properties\n",
    "    assert_compatibilities(arguments)\n",
    "    \n",
    "    model1: GeneralModel = find_right_model(\n",
    "        NETWORKS_DIR, arguments['model'],\n",
    "        device=arguments['device'],\n",
    "        hidden_dim=arguments['hidden_dim'],\n",
    "        input_dim=arguments['input_dim'],\n",
    "        output_dim=arguments['output_dim'],\n",
    "        is_maskable=arguments['disable_masking'],\n",
    "        is_tracking_weights=arguments['track_weights'],\n",
    "        is_rewindable=arguments['enable_rewinding'],\n",
    "        is_growable=arguments['growing_rate'] > 0,\n",
    "        outer_layer_pruning=arguments['outer_layer_pruning'],\n",
    "        maintain_outer_mask_anyway=(\n",
    "                                       not arguments['outer_layer_pruning']) and (\n",
    "                                           \"Structured\" in arguments['prune_criterion']),\n",
    "        l0=arguments['l0'],\n",
    "        l0_reg=arguments['l0_reg'],\n",
    "        N=arguments['N'],\n",
    "        beta_ema=arguments['beta_ema'],\n",
    "        l2_reg=arguments['l2_reg']\n",
    "    ).to(arguments['device'])\n",
    "    model2: GeneralModel = find_right_model(\n",
    "        NETWORKS_DIR, arguments['model'],\n",
    "        device=arguments['device'],\n",
    "        hidden_dim=arguments['hidden_dim'],\n",
    "        input_dim=arguments['input_dim'],\n",
    "        output_dim=arguments['output_dim'],\n",
    "        is_maskable=arguments['disable_masking'],\n",
    "        is_tracking_weights=arguments['track_weights'],\n",
    "        is_rewindable=arguments['enable_rewinding'],\n",
    "        is_growable=arguments['growing_rate'] > 0,\n",
    "        outer_layer_pruning=arguments['outer_layer_pruning'],\n",
    "        maintain_outer_mask_anyway=(\n",
    "                                       not arguments['outer_layer_pruning']) and (\n",
    "                                           \"Structured\" in arguments['prune_criterion']),\n",
    "        l0=arguments['l0'],\n",
    "        l0_reg=arguments['l0_reg'],\n",
    "        N=arguments['N'],\n",
    "        beta_ema=arguments['beta_ema'],\n",
    "        l2_reg=arguments['l2_reg']\n",
    "    ).to(arguments['device'])\n",
    "    model3: GeneralModel = find_right_model(\n",
    "        NETWORKS_DIR, arguments['model'],\n",
    "        device=arguments['device'],\n",
    "        hidden_dim=arguments['hidden_dim'],\n",
    "        input_dim=arguments['input_dim'],\n",
    "        output_dim=arguments['output_dim'],\n",
    "        is_maskable=arguments['disable_masking'],\n",
    "        is_tracking_weights=arguments['track_weights'],\n",
    "        is_rewindable=arguments['enable_rewinding'],\n",
    "        is_growable=arguments['growing_rate'] > 0,\n",
    "        outer_layer_pruning=arguments['outer_layer_pruning'],\n",
    "        maintain_outer_mask_anyway=(\n",
    "                                       not arguments['outer_layer_pruning']) and (\n",
    "                                           \"Structured\" in arguments['prune_criterion']),\n",
    "        l0=arguments['l0'],\n",
    "        l0_reg=arguments['l0_reg'],\n",
    "        N=arguments['N'],\n",
    "        beta_ema=arguments['beta_ema'],\n",
    "        l2_reg=arguments['l2_reg']\n",
    "    ).to(arguments['device'])\n",
    "    model4: GeneralModel = find_right_model(\n",
    "        NETWORKS_DIR, arguments['model'],\n",
    "        device=arguments['device'],\n",
    "        hidden_dim=arguments['hidden_dim'],\n",
    "        input_dim=arguments['input_dim'],\n",
    "        output_dim=arguments['output_dim'],\n",
    "        is_maskable=arguments['disable_masking'],\n",
    "        is_tracking_weights=arguments['track_weights'],\n",
    "        is_rewindable=arguments['enable_rewinding'],\n",
    "        is_growable=arguments['growing_rate'] > 0,\n",
    "        outer_layer_pruning=arguments['outer_layer_pruning'],\n",
    "        maintain_outer_mask_anyway=(\n",
    "                                       not arguments['outer_layer_pruning']) and (\n",
    "                                           \"Structured\" in arguments['prune_criterion']),\n",
    "        l0=arguments['l0'],\n",
    "        l0_reg=arguments['l0_reg'],\n",
    "        N=arguments['N'],\n",
    "        beta_ema=arguments['beta_ema'],\n",
    "        l2_reg=arguments['l2_reg']\n",
    "    ).to(arguments['device'])\n",
    "    model5: GeneralModel = find_right_model(\n",
    "        NETWORKS_DIR, arguments['model'],\n",
    "        device=arguments['device'],\n",
    "        hidden_dim=arguments['hidden_dim'],\n",
    "        input_dim=arguments['input_dim'],\n",
    "        output_dim=arguments['output_dim'],\n",
    "        is_maskable=arguments['disable_masking'],\n",
    "        is_tracking_weights=arguments['track_weights'],\n",
    "        is_rewindable=arguments['enable_rewinding'],\n",
    "        is_growable=arguments['growing_rate'] > 0,\n",
    "        outer_layer_pruning=arguments['outer_layer_pruning'],\n",
    "        maintain_outer_mask_anyway=(\n",
    "                                       not arguments['outer_layer_pruning']) and (\n",
    "                                           \"Structured\" in arguments['prune_criterion']),\n",
    "        l0=arguments['l0'],\n",
    "        l0_reg=arguments['l0_reg'],\n",
    "        N=arguments['N'],\n",
    "        beta_ema=arguments['beta_ema'],\n",
    "        l2_reg=arguments['l2_reg']\n",
    "    ).to(arguments['device'])\n",
    "\n",
    "    # load pre-trained weights if specified\n",
    " #  \n",
    "#     path1 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNetAfter/2021-08-05_11.29.38_model=ResNet18_dataset=CIFAR10_ood-dataset=SVHN_attack=FGSM_epsilon=6_prune-criterion=SNIP_pruning-limit=0.94_prune-freq=1_prune-delay=0_rewind-to=0_train-scheme=DefaultTrainer_seed=1234/models/ResNet18_finished.pickle'\n",
    "#     path2 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNetAfter/2021-08-05_11.23.29_model=ResNet18_dataset=CIFAR10_ood-dataset=SVHN_attack=FGSM_epsilon=6_prune-criterion=SNIP_pruning-limit=0.94_prune-freq=1_prune-delay=0_rewind-to=0_train-scheme=DefaultTrainer_seed=2345/models/ResNet18_finished.pickle'\n",
    "#     path3 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNetAfter/2021-08-05_11.36.02_model=ResNet18_dataset=CIFAR10_ood-dataset=SVHN_attack=FGSM_epsilon=6_prune-criterion=SNIP_pruning-limit=0.94_prune-freq=1_prune-delay=0_rewind-to=0_train-scheme=DefaultTrainer_seed=3456/models/ResNet18_finished.pickle'\n",
    "#     path4 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNetAfter/2021-08-05_11.40.55_model=ResNet18_dataset=CIFAR10_ood-dataset=SVHN_attack=FGSM_epsilon=6_prune-criterion=SNIP_pruning-limit=0.94_prune-freq=1_prune-delay=0_rewind-to=0_train-scheme=DefaultTrainer_seed=4567/models/ResNet18_finished.pickle'\n",
    "#     path5 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNetAfter/2021-08-05_11.45.37_model=ResNet18_dataset=CIFAR10_ood-dataset=SVHN_attack=FGSM_epsilon=6_prune-criterion=SNIP_pruning-limit=0.94_prune-freq=1_prune-delay=0_rewind-to=0_train-scheme=DefaultTrainer_seed=5678/models/ResNet18_finished.pickle'\n",
    "\n",
    "    path1 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_22.46.19_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=1234/models/ResNet18_finished.pickle'\n",
    "    path2 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_23.33.17_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=2345/models/ResNet18_finished.pickle'\n",
    "    path3 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_23.35.18_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=3456/models/ResNet18_finished.pickle'\n",
    "    path4 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_23.35.46_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=4567/models/ResNet18_finished.pickle'\n",
    "    path5 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_23.36.23_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=5678/models/ResNet18_finished.pickle'\n",
    "    \n",
    "    load_checkpoint(path1, model1, out)\n",
    "    load_checkpoint(path2, model2, out)\n",
    "    load_checkpoint(path3, model3, out)\n",
    "    load_checkpoint(path4, model4, out)\n",
    "    load_checkpoint(path5, model5, out)\n",
    "\n",
    "    ensembles = [model1, model2, model3, model4, model5]\n",
    "#     ensembles = [model1]\n",
    "\n",
    "    # load data\n",
    "    train_loader, test_loader = find_right_model(\n",
    "        DATASETS, arguments['data_set'],\n",
    "        arguments=arguments\n",
    "    )\n",
    "\n",
    "    # load OOD data\n",
    "    _, ood_loader = find_right_model(\n",
    "        DATASETS, arguments['ood_data_set'],\n",
    "        arguments=arguments\n",
    "    )\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    import time\n",
    "    acc = []\n",
    "    inf_time = []\n",
    "    with torch.no_grad():\n",
    "        for batch_num, batch in enumerate(test_loader):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            output = 0\n",
    "            start = time.time()\n",
    "            for model in ensembles:\n",
    "                output += model(x)\n",
    "            end = time.time()\n",
    "            inf_time.append(end-start)\n",
    "            output /= len(ensembles)\n",
    "            probs = F.softmax(output, dim=-1)\n",
    "\n",
    "            predictions = probs.argmax(dim=-1, keepdim=True).view_as(y)\n",
    "            correct = y.eq(predictions).sum().item()\n",
    "            acc.append(correct / output.shape[0])\n",
    "        \n",
    "    results['accuracy'] = np.mean(acc)\n",
    "    results['inference_time'] = np.mean(inf_time)\n",
    "    \n",
    "    out(\"EVALUATING...\")\n",
    "    \n",
    "    for model in ensembles:\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ood_data_set in arguments['eval_ood_data_sets']:\n",
    "            out(\"OOD Dataset: {}\".format(ood_data_set))\n",
    "            # load data\n",
    "            _, test_loader = find_right_model(\n",
    "                DATASETS, arguments['data_set'],\n",
    "                arguments=arguments\n",
    "            )\n",
    "\n",
    "            # load OOD data\n",
    "            _, ood_loader = find_right_model(\n",
    "                DATASETS, ood_data_set,\n",
    "                arguments=arguments\n",
    "            )\n",
    "            # build tester\n",
    "            tester = find_right_model(\n",
    "                TESTERS_DIR, 'OODEvaluation',\n",
    "                model=ensembles,\n",
    "                device=device,\n",
    "                arguments=None,\n",
    "                test_loader=test_loader,\n",
    "                ood_loader=ood_loader,\n",
    "                ood_dataset=ood_data_set,\n",
    "                ensemble=True\n",
    "            )\n",
    "            res = tester.evaluate()\n",
    "\n",
    "            for key, value in res.items():\n",
    "                results[key] = value\n",
    "\n",
    "    class DS(Dataset):\n",
    "\n",
    "        def __init__(self, images, labels):\n",
    "            self.images = images\n",
    "            self.labels = labels\n",
    "            self.mean = [0.4914, 0.4822, 0.4465]\n",
    "            self.std = [0.2471, 0.2435, 0.2616]\n",
    "            self.transforms = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=self.mean, std=self.std)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        def __getitem__(self, item):\n",
    "            image = self.images[item] / 255\n",
    "            image = self.transforms(image.transpose((1, 2, 0)))\n",
    "            return image.to(torch.float32), torch.tensor(self.labels[item], dtype=torch.float32)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.images)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if arguments[\"data_set\"] == \"CIFAR10\":\n",
    "            avg_acc = np.zeros(5)\n",
    "            avg_entropy = np.zeros(5)\n",
    "            avg_auroc = np.zeros(5)\n",
    "            avg_aupr = np.zeros(5)\n",
    "            avg_auroc_ent = np.zeros(5)\n",
    "            avg_aupr_ent = np.zeros(5)\n",
    "            ds_path = os.path.join(DATASET_PATH, \"cifar10_corrupted\")\n",
    "            for ds_dataset_name in os.listdir(ds_path):\n",
    "                npz_dataset = np.load(os.path.join(ds_path, ds_dataset_name))\n",
    "\n",
    "                ds_dataset = DS(npz_dataset[\"images\"], npz_dataset[\"labels\"])\n",
    "                ds_loader = torch.utils.data.DataLoader(\n",
    "                    ds_dataset,\n",
    "                    batch_size=arguments['batch_size'],\n",
    "                    shuffle=False,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=4\n",
    "                )\n",
    "\n",
    "                # build tester\n",
    "                tester = find_right_model(\n",
    "                    TESTERS_DIR, 'DSEvaluation',\n",
    "                    model=ensembles,\n",
    "                    device=device,\n",
    "                    arguments=None,\n",
    "                    test_loader=test_loader,\n",
    "                    ds_loader=ds_loader,\n",
    "                    ds_dataset=ds_dataset_name.split('.')[0],\n",
    "                    ensemble=True\n",
    "                )\n",
    "                res = tester.evaluate()\n",
    "\n",
    "                severity = int(ds_dataset_name.split('.')[0].split('_')[-1]) - 1\n",
    "                for key, value in res.items():\n",
    "                    if key.startswith('acc'):\n",
    "                        avg_acc[severity] += value\n",
    "                    elif key.startswith('auroc_entropy'):\n",
    "                        avg_auroc_ent[severity] += value\n",
    "                    elif key.startswith('aupr_entropy'):\n",
    "                        avg_aupr_ent[severity] += value\n",
    "                    elif key.startswith('auroc'):\n",
    "                        avg_auroc[severity] += value\n",
    "                    elif key.startswith('aupr'):\n",
    "                        avg_aupr[severity] += value\n",
    "                    elif key.startswith('entropy_'):\n",
    "                        avg_entropy[severity] += value\n",
    "\n",
    "                    results[key] = value\n",
    "            avg_acc = avg_acc / 15\n",
    "            avg_auroc_ent = avg_auroc_ent / 15\n",
    "            avg_aupr_ent = avg_aupr_ent / 15\n",
    "            avg_auroc = avg_auroc / 15\n",
    "            avg_aupr = avg_aupr / 15\n",
    "            avg_entropy = avg_entropy / 15\n",
    "            for i in range(len(avg_acc)):\n",
    "                name = 'avg_acc_' + str(i + 1)\n",
    "                results[name] = avg_acc[i]\n",
    "            for i in range(len(avg_acc)):\n",
    "                name = 'avg_auroc_ent_' + str(i + 1)\n",
    "                results[name] = avg_auroc_ent[i]\n",
    "            for i in range(len(avg_acc)):\n",
    "                name = 'avg_aupr_ent_' + str(i + 1)\n",
    "                results[name] = avg_aupr_ent[i]\n",
    "            for i in range(len(avg_acc)):\n",
    "                name = 'avg_auroc_' + str(i + 1)\n",
    "                results[name] = avg_auroc[i]\n",
    "            for i in range(len(avg_acc)):\n",
    "                name = 'avg_aupr_' + str(i + 1)\n",
    "                results[name] = avg_aupr[i]\n",
    "            for i in range(len(avg_acc)):\n",
    "                name = 'avg_entropy_' + str(i + 1)\n",
    "                results[name] = avg_entropy[i]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def assert_compatibilities(arguments):\n",
    "    check_incompatible_props([arguments['loss'] != \"L0CrossEntropy\", arguments['l0']], \"l0\", arguments['loss'])\n",
    "    check_incompatible_props([arguments['train_scheme'] != \"L0Trainer\", arguments['l0']], \"l0\", arguments['train_scheme'])\n",
    "    check_incompatible_props([arguments['l0'], arguments['group_hoyer_square'], arguments['hoyer_square']],\n",
    "                             \"Choose one mode, not multiple\")\n",
    "    check_incompatible_props(\n",
    "        [\"Structured\" in arguments['prune_criterion'], \"Group\" in arguments['prune_criterion'], \"ResNet\" in arguments['model']],\n",
    "        \"structured\", \"residual connections\")\n",
    "    # todo: add more\n",
    "\n",
    "\n",
    "def load_checkpoint(path, model, out):\n",
    "    with open(path, 'rb') as f:\n",
    "        state = pickle.load(f)\n",
    "    try:\n",
    "        model.load_state_dict(state)\n",
    "    except KeyError as e:\n",
    "        print(list(state.keys()))\n",
    "        raise e\n",
    "    out(f\"Loaded checkpoint {path}\")\n",
    "\n",
    "\n",
    "def log_start_run(arguments, out):\n",
    "    arguments.PyTorch_version = torch.__version__\n",
    "    arguments.PyThon_version = sys.version\n",
    "    arguments.pwd = os.getcwd()\n",
    "    out(\"PyTorch version:\", torch.__version__, \"Python version:\", sys.version)\n",
    "    out(\"Working directory: \", os.getcwd())\n",
    "    out(\"CUDA avalability:\", torch.cuda.is_available(), \"CUDA version:\", torch.version.cuda)\n",
    "    out(arguments)\n",
    "\n",
    "def run(arguments):\n",
    "    metrics = Metrics()\n",
    "    out = metrics.log_line\n",
    "    metrics._batch_size = arguments['batch_size']\n",
    "    metrics._eval_freq = arguments['eval_freq']\n",
    "    set_results_dir(arguments[\"results_dir\"])\n",
    "    return main(arguments, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at 2021-08-05_14.23.27\n",
      "Ignored arguments in ResNet18: {'hidden_dim': [512]}\n",
      "10\n",
      "Ignored arguments in ResNet18: {'hidden_dim': [512]}\n",
      "10\n",
      "Ignored arguments in ResNet18: {'hidden_dim': [512]}\n",
      "10\n",
      "Ignored arguments in ResNet18: {'hidden_dim': [512]}\n",
      "10\n",
      "Ignored arguments in ResNet18: {'hidden_dim': [512]}\n",
      "10\n",
      "Loaded checkpoint /nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_22.46.19_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=1234/models/ResNet18_finished.pickle\n",
      "Loaded checkpoint /nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_23.33.17_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=2345/models/ResNet18_finished.pickle\n",
      "Loaded checkpoint /nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_23.35.18_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=3456/models/ResNet18_finished.pickle\n",
      "Loaded checkpoint /nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_23.35.46_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=4567/models/ResNet18_finished.pickle\n",
      "Loaded checkpoint /nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-07-26_23.36.23_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=10_rewind-to=0_train-scheme=DefaultTrainer_seed=5678/models/ResNet18_finished.pickle\n",
      "Using downloaded and verified file: gitignored/data/train_32x32.mat\n",
      "Using downloaded and verified file: gitignored/data/test_32x32.mat\n",
      "EVALUATING...\n",
      "OOD Dataset: SVHN\n",
      "Using downloaded and verified file: gitignored/data/train_32x32.mat\n",
      "Using downloaded and verified file: gitignored/data/test_32x32.mat\n",
      "OOD Dataset: CIFAR100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "results = run(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.93779296875,\n",
       " 'inference_time': 0.05590952634811401,\n",
       " 'conf_auroc': 0.936158578378669,\n",
       " 'conf_aupr': 0.9957560716749201,\n",
       " 'brier_score': 0.09446179,\n",
       " 'entropy': 0.11242550221445197,\n",
       " 'auroc_SVHN': 0.9451778272894898,\n",
       " 'aupr_SVHN': 0.9294776554952111,\n",
       " 'entropy_SVHN': 0.9259864292387263,\n",
       " 'auroc_entropy_SVHN': 0.9542136677934849,\n",
       " 'aupr_entropy_SVHN': 0.9710305710685367,\n",
       " 'auroc_CIFAR100': 0.8881945400000002,\n",
       " 'aupr_CIFAR100': 0.9055586967203131,\n",
       " 'entropy_CIFAR100': 0.6941687940405482,\n",
       " 'auroc_entropy_CIFAR100': 0.8945123199999999,\n",
       " 'aupr_entropy_CIFAR100': 0.8709381431856201,\n",
       " 'acc_impulse_noise_5': 0.19607077205882353,\n",
       " 'auroc_impulse_noise_5': 0.959626935,\n",
       " 'aupr_impulse_noise_5': 0.9714581885930962,\n",
       " 'entropy_impulse_noise_5': 1.0937763597167096,\n",
       " 'auroc_entropy_impulse_noise_5': 0.96965297,\n",
       " 'aupr_entropy_impulse_noise_5': 0.9552877796275125,\n",
       " 'acc_pixelate_1': 0.9166877297794118,\n",
       " 'auroc_pixelate_1': 0.56968463,\n",
       " 'aupr_pixelate_1': 0.558621315279711,\n",
       " 'entropy_pixelate_1': 0.1670710102777447,\n",
       " 'auroc_entropy_pixelate_1': 0.5714507500000001,\n",
       " 'aupr_entropy_pixelate_1': 0.5615465673262204,\n",
       " 'acc_snow_3': 0.8194221047794118,\n",
       " 'auroc_snow_3': 0.6961502799999999,\n",
       " 'aupr_snow_3': 0.694729218753199,\n",
       " 'entropy_snow_3': 0.2874709607909608,\n",
       " 'auroc_entropy_snow_3': 0.698575745,\n",
       " 'aupr_entropy_snow_3': 0.6731675647741218,\n",
       " 'acc_elastic_1': 0.8998334099264707,\n",
       " 'auroc_elastic_1': 0.623645185,\n",
       " 'aupr_elastic_1': 0.6223017216683544,\n",
       " 'entropy_elastic_1': 0.19336038358603713,\n",
       " 'auroc_entropy_elastic_1': 0.6252167500000001,\n",
       " 'aupr_entropy_elastic_1': 0.5968342843289516,\n",
       " 'acc_pixelate_5': 0.4298368566176471,\n",
       " 'auroc_pixelate_5': 0.840746285,\n",
       " 'aupr_pixelate_5': 0.8415546741438578,\n",
       " 'entropy_pixelate_5': 0.6613839240714072,\n",
       " 'auroc_entropy_pixelate_5': 0.8472887,\n",
       " 'aupr_entropy_pixelate_5': 0.8430348761208254,\n",
       " 'acc_jpeg_compression_1': 0.8636603860294118,\n",
       " 'auroc_jpeg_compression_1': 0.66977407,\n",
       " 'aupr_jpeg_compression_1': 0.6705992130654205,\n",
       " 'entropy_jpeg_compression_1': 0.24894848983551301,\n",
       " 'auroc_entropy_jpeg_compression_1': 0.67228435,\n",
       " 'aupr_entropy_jpeg_compression_1': 0.6452171178585335,\n",
       " 'acc_defocus_blur_5': 0.5896197150735294,\n",
       " 'auroc_defocus_blur_5': 0.856768985,\n",
       " 'aupr_defocus_blur_5': 0.8769509660864933,\n",
       " 'entropy_defocus_blur_5': 0.5657227377606783,\n",
       " 'auroc_entropy_defocus_blur_5': 0.8621211350000001,\n",
       " 'aupr_entropy_defocus_blur_5': 0.8292358198509616,\n",
       " 'acc_brightness_3': 0.9378216911764706,\n",
       " 'auroc_brightness_3': 0.500820505,\n",
       " 'aupr_brightness_3': 0.5031957613765946,\n",
       " 'entropy_brightness_3': 0.10986381749486343,\n",
       " 'auroc_entropy_brightness_3': 0.500714385,\n",
       " 'aupr_entropy_brightness_3': 0.49837677868190033,\n",
       " 'acc_impulse_noise_1': 0.8402056525735293,\n",
       " 'auroc_impulse_noise_1': 0.666880605,\n",
       " 'aupr_impulse_noise_1': 0.6609840524809693,\n",
       " 'entropy_impulse_noise_1': 0.2623240004070484,\n",
       " 'auroc_entropy_impulse_noise_1': 0.66948065,\n",
       " 'aupr_entropy_impulse_noise_1': 0.6503503525501456,\n",
       " 'acc_shot_noise_3': 0.47337431066176466,\n",
       " 'auroc_shot_noise_3': 0.861738815,\n",
       " 'aupr_shot_noise_3': 0.8788331604593502,\n",
       " 'entropy_shot_noise_3': 0.6102651639829832,\n",
       " 'auroc_entropy_shot_noise_3': 0.8675670149999999,\n",
       " 'aupr_entropy_shot_noise_3': 0.8419733099195127,\n",
       " 'acc_frosted_glass_blur_5': 0.4510282628676471,\n",
       " 'auroc_frosted_glass_blur_5': 0.8627345599999999,\n",
       " 'aupr_frosted_glass_blur_5': 0.8785960361497162,\n",
       " 'entropy_frosted_glass_blur_5': 0.6631133480929441,\n",
       " 'auroc_entropy_frosted_glass_blur_5': 0.8693444150000001,\n",
       " 'aupr_entropy_frosted_glass_blur_5': 0.8540836000233988,\n",
       " 'acc_jpeg_compression_3': 0.7845530790441176,\n",
       " 'auroc_jpeg_compression_3': 0.75612033,\n",
       " 'aupr_jpeg_compression_3': 0.768632245625861,\n",
       " 'entropy_jpeg_compression_3': 0.3689878871935908,\n",
       " 'auroc_entropy_jpeg_compression_3': 0.75951434,\n",
       " 'aupr_entropy_jpeg_compression_3': 0.7303474303505182,\n",
       " 'acc_frosted_glass_blur_1': 0.5075482536764706,\n",
       " 'auroc_frosted_glass_blur_1': 0.8553543300000002,\n",
       " 'aupr_frosted_glass_blur_1': 0.8701950277708248,\n",
       " 'entropy_frosted_glass_blur_1': 0.6424789206089233,\n",
       " 'auroc_entropy_frosted_glass_blur_1': 0.86181831,\n",
       " 'aupr_entropy_frosted_glass_blur_1': 0.8468932568132359,\n",
       " 'acc_defocus_blur_3': 0.8803825827205882,\n",
       " 'auroc_defocus_blur_3': 0.6303864399999999,\n",
       " 'aupr_defocus_blur_3': 0.6256690066173732,\n",
       " 'entropy_defocus_blur_3': 0.19924733807841552,\n",
       " 'auroc_entropy_defocus_blur_3': 0.63150453,\n",
       " 'aupr_entropy_defocus_blur_3': 0.6017625868349239,\n",
       " 'acc_shot_noise_5': 0.24659926470588234,\n",
       " 'auroc_shot_noise_5': 0.922775115,\n",
       " 'aupr_shot_noise_5': 0.9416092149404621,\n",
       " 'entropy_shot_noise_5': 0.785677450872046,\n",
       " 'auroc_entropy_shot_noise_5': 0.9286087,\n",
       " 'aupr_entropy_shot_noise_5': 0.8993630420427192,\n",
       " 'acc_defocus_blur_1': 0.9412971047794118,\n",
       " 'auroc_defocus_blur_1': 0.505821625,\n",
       " 'aupr_defocus_blur_1': 0.5050200322645775,\n",
       " 'entropy_defocus_blur_1': 0.11323256425276622,\n",
       " 'auroc_entropy_defocus_blur_1': 0.50596222,\n",
       " 'aupr_entropy_defocus_blur_1': 0.5029850522519794,\n",
       " 'acc_frosted_glass_blur_3': 0.5879078584558823,\n",
       " 'auroc_frosted_glass_blur_3': 0.824340135,\n",
       " 'aupr_frosted_glass_blur_3': 0.8354654229711691,\n",
       " 'entropy_frosted_glass_blur_3': 0.5567921772685902,\n",
       " 'auroc_entropy_frosted_glass_blur_3': 0.829835255,\n",
       " 'aupr_entropy_frosted_glass_blur_3': 0.8144013513264636,\n",
       " 'acc_jpeg_compression_5': 0.7258099724264706,\n",
       " 'auroc_jpeg_compression_5': 0.7982042500000001,\n",
       " 'aupr_jpeg_compression_5': 0.8148284042515382,\n",
       " 'entropy_jpeg_compression_5': 0.44530663111578844,\n",
       " 'auroc_entropy_jpeg_compression_5': 0.80241797,\n",
       " 'aupr_entropy_jpeg_compression_5': 0.7735107469757543,\n",
       " 'acc_frost_1': 0.9136833639705882,\n",
       " 'auroc_frost_1': 0.55783674,\n",
       " 'aupr_frost_1': 0.5492128914682037,\n",
       " 'entropy_frost_1': 0.15005642100591177,\n",
       " 'auroc_entropy_frost_1': 0.5585593550000001,\n",
       " 'aupr_entropy_frost_1': 0.5454278905354605,\n",
       " 'acc_gaussian_noise_1': 0.7788143382352941,\n",
       " 'auroc_gaussian_noise_1': 0.71808575,\n",
       " 'aupr_gaussian_noise_1': 0.7149834384458504,\n",
       " 'entropy_gaussian_noise_1': 0.324117009492494,\n",
       " 'auroc_entropy_gaussian_noise_1': 0.72103261,\n",
       " 'aupr_entropy_gaussian_noise_1': 0.6966488930263702,\n",
       " 'acc_zoom_blur_5': 0.6523265165441177,\n",
       " 'auroc_zoom_blur_5': 0.8203148600000001,\n",
       " 'aupr_zoom_blur_5': 0.8352025855014213,\n",
       " 'entropy_zoom_blur_5': 0.48043270990985276,\n",
       " 'auroc_entropy_zoom_blur_5': 0.82487023,\n",
       " 'aupr_entropy_zoom_blur_5': 0.791790598933678,\n",
       " 'acc_brightness_5': 0.9142463235294118,\n",
       " 'auroc_brightness_5': 0.58005398,\n",
       " 'aupr_brightness_5': 0.5786063271004525,\n",
       " 'entropy_brightness_5': 0.15605269733670926,\n",
       " 'auroc_entropy_brightness_5': 0.5812902,\n",
       " 'aupr_entropy_brightness_5': 0.5585791172129699,\n",
       " 'acc_motion_blur_1': 0.8978400735294118,\n",
       " 'auroc_motion_blur_1': 0.6060485,\n",
       " 'aupr_motion_blur_1': 0.5999113691849515,\n",
       " 'entropy_motion_blur_1': 0.17819960524030135,\n",
       " 'auroc_entropy_motion_blur_1': 0.60706912,\n",
       " 'aupr_entropy_motion_blur_1': 0.5810253724251071,\n",
       " 'acc_pixelate_3': 0.8104664522058824,\n",
       " 'auroc_pixelate_3': 0.6871495249999999,\n",
       " 'aupr_pixelate_3': 0.6655122454572386,\n",
       " 'entropy_pixelate_3': 0.34119709021619,\n",
       " 'auroc_entropy_pixelate_3': 0.69126705,\n",
       " 'aupr_entropy_pixelate_3': 0.691596166827297,\n",
       " 'acc_gaussian_noise_3': 0.30837545955882356,\n",
       " 'auroc_gaussian_noise_3': 0.89285915,\n",
       " 'aupr_gaussian_noise_3': 0.9137776009557648,\n",
       " 'entropy_gaussian_noise_3': 0.6695471914251748,\n",
       " 'auroc_entropy_gaussian_noise_3': 0.89840631,\n",
       " 'aupr_entropy_gaussian_noise_3': 0.8664520276934021,\n",
       " 'acc_fog_1': 0.9459041819852942,\n",
       " 'auroc_fog_1': 0.48370126999999996,\n",
       " 'aupr_fog_1': 0.4877571236180794,\n",
       " 'entropy_fog_1': 0.1012055703611955,\n",
       " 'auroc_entropy_fog_1': 0.482996635,\n",
       " 'aupr_entropy_fog_1': 0.48626438644494807,\n",
       " 'acc_brightness_1': 0.9448184742647058,\n",
       " 'auroc_brightness_1': 0.488829025,\n",
       " 'aupr_brightness_1': 0.49210099772849286,\n",
       " 'entropy_brightness_1': 0.10477163905022055,\n",
       " 'auroc_entropy_brightness_1': 0.4885497,\n",
       " 'aupr_entropy_brightness_1': 0.4906727669875828,\n",
       " 'acc_contrast_3': 0.8944508272058824,\n",
       " 'auroc_contrast_3': 0.6184835099999999,\n",
       " 'aupr_contrast_3': 0.6187846887576822,\n",
       " 'entropy_contrast_3': 0.18394796023535978,\n",
       " 'auroc_entropy_contrast_3': 0.620085175,\n",
       " 'aupr_entropy_contrast_3': 0.5892994415084746,\n",
       " 'acc_motion_blur_3': 0.7296645220588236,\n",
       " 'auroc_motion_blur_3': 0.7747854350000001,\n",
       " 'aupr_motion_blur_3': 0.7872483585670658,\n",
       " 'entropy_motion_blur_3': 0.3840182098957579,\n",
       " 'auroc_entropy_motion_blur_3': 0.777824185,\n",
       " 'aupr_entropy_motion_blur_3': 0.7423003470158697,\n",
       " 'acc_frost_5': 0.6343807444852941,\n",
       " 'auroc_frost_5': 0.7855156050000001,\n",
       " 'aupr_frost_5': 0.7868745717862249,\n",
       " 'entropy_frost_5': 0.44740449681203537,\n",
       " 'auroc_entropy_frost_5': 0.7898029000000001,\n",
       " 'aupr_entropy_frost_5': 0.7670429997419284,\n",
       " 'acc_snow_5': 0.7445427389705882,\n",
       " 'auroc_snow_5': 0.7590483849999999,\n",
       " 'aupr_snow_5': 0.7659749836817882,\n",
       " 'entropy_snow_5': 0.37950585355513394,\n",
       " 'auroc_entropy_snow_5': 0.762487195,\n",
       " 'aupr_entropy_snow_5': 0.7341678834485754,\n",
       " 'acc_elastic_3': 0.8553883272058824,\n",
       " 'auroc_elastic_3': 0.67904931,\n",
       " 'aupr_elastic_3': 0.6856324197546636,\n",
       " 'entropy_elastic_3': 0.24383287325501365,\n",
       " 'auroc_entropy_elastic_3': 0.680442955,\n",
       " 'aupr_entropy_elastic_3': 0.6442326052079969,\n",
       " 'acc_fog_3': 0.9245232077205883,\n",
       " 'auroc_fog_3': 0.549761025,\n",
       " 'aupr_fog_3': 0.5451133507530659,\n",
       " 'entropy_fog_3': 0.1351434191710219,\n",
       " 'auroc_entropy_fog_3': 0.5502871650000001,\n",
       " 'aupr_entropy_fog_3': 0.5332152417688327,\n",
       " 'acc_gaussian_noise_5': 0.20043083639705883,\n",
       " 'auroc_gaussian_noise_5': 0.91998924,\n",
       " 'aupr_gaussian_noise_5': 0.9414894151533559,\n",
       " 'entropy_gaussian_noise_5': 0.7321943932976653,\n",
       " 'auroc_entropy_gaussian_noise_5': 0.9251433400000001,\n",
       " 'aupr_entropy_gaussian_noise_5': 0.88635863688513,\n",
       " 'acc_contrast_1': 0.9430434283088236,\n",
       " 'auroc_contrast_1': 0.488184285,\n",
       " 'aupr_contrast_1': 0.4915368278797127,\n",
       " 'entropy_contrast_1': 0.10345721473620581,\n",
       " 'auroc_entropy_contrast_1': 0.487658885,\n",
       " 'aupr_entropy_contrast_1': 0.4892934278716442,\n",
       " 'acc_motion_blur_5': 0.6410271139705882,\n",
       " 'auroc_motion_blur_5': 0.82734118,\n",
       " 'aupr_motion_blur_5': 0.84507511562391,\n",
       " 'entropy_motion_blur_5': 0.49567501066298203,\n",
       " 'auroc_entropy_motion_blur_5': 0.8316467900000002,\n",
       " 'aupr_entropy_motion_blur_5': 0.7991053627433471,\n",
       " 'acc_shot_noise_1': 0.85205078125,\n",
       " 'auroc_shot_noise_1': 0.6451562399999999,\n",
       " 'aupr_shot_noise_1': 0.632266070388847,\n",
       " 'entropy_shot_noise_1': 0.2362622667935201,\n",
       " 'auroc_entropy_shot_noise_1': 0.6476513500000001,\n",
       " 'aupr_entropy_shot_noise_1': 0.6276920010744989,\n",
       " 'acc_zoom_blur_3': 0.7907513786764706,\n",
       " 'auroc_zoom_blur_3': 0.735264315,\n",
       " 'aupr_zoom_blur_3': 0.7425830050384454,\n",
       " 'entropy_zoom_blur_3': 0.3232903449769016,\n",
       " 'auroc_entropy_zoom_blur_3': 0.7377865100000001,\n",
       " 'aupr_entropy_zoom_blur_3': 0.7030838857714486,\n",
       " 'acc_fog_5': 0.7531307444852942,\n",
       " 'auroc_fog_5': 0.7494809450000001,\n",
       " 'aupr_fog_5': 0.7525864362775931,\n",
       " 'entropy_fog_5': 0.36650853130395306,\n",
       " 'auroc_entropy_fog_5': 0.7525862249999999,\n",
       " 'aupr_entropy_fog_5': 0.724715038443563,\n",
       " 'acc_zoom_blur_1': 0.8691004136029411,\n",
       " 'auroc_zoom_blur_1': 0.6540441450000001,\n",
       " 'aupr_zoom_blur_1': 0.6486226701680496,\n",
       " 'entropy_zoom_blur_1': 0.2288918837229077,\n",
       " 'auroc_entropy_zoom_blur_1': 0.6558857849999999,\n",
       " 'aupr_entropy_zoom_blur_1': 0.627303295616737,\n",
       " 'acc_snow_1': 0.8885052849264706,\n",
       " 'auroc_snow_1': 0.6014674950000001,\n",
       " 'aupr_snow_1': 0.5917317992280678,\n",
       " 'entropy_snow_1': 0.18486675244844644,\n",
       " 'auroc_entropy_snow_1': 0.6028250100000001,\n",
       " 'aupr_entropy_snow_1': 0.5835289441226532,\n",
       " 'acc_elastic_5': 0.7563189338235294,\n",
       " 'auroc_elastic_5': 0.782360335,\n",
       " 'aupr_elastic_5': 0.8009826652501095,\n",
       " 'entropy_elastic_5': 0.3982379578229325,\n",
       " 'auroc_entropy_elastic_5': 0.78525506,\n",
       " 'aupr_entropy_elastic_5': 0.7510513462465579,\n",
       " 'acc_frost_3': 0.7651941636029412,\n",
       " 'auroc_frost_3': 0.72145199,\n",
       " 'aupr_frost_3': 0.7158297840919364,\n",
       " 'entropy_frost_3': 0.33836889664311837,\n",
       " 'auroc_entropy_frost_3': 0.72471729,\n",
       " 'aupr_entropy_frost_3': 0.7029025235244182,\n",
       " 'acc_contrast_5': 0.4023035386029412,\n",
       " 'auroc_contrast_5': 0.9165013650000001,\n",
       " 'aupr_contrast_5': 0.934762781886092,\n",
       " 'entropy_contrast_5': 0.843586941302337,\n",
       " 'auroc_entropy_contrast_5': 0.92889525,\n",
       " 'aupr_entropy_contrast_5': 0.9087423625495985,\n",
       " 'acc_impulse_noise_3': 0.5961511948529412,\n",
       " 'auroc_impulse_noise_3': 0.86198123,\n",
       " 'aupr_impulse_noise_3': 0.8766731114073296,\n",
       " 'entropy_impulse_noise_3': 0.6965735243929195,\n",
       " 'auroc_entropy_impulse_noise_3': 0.869517855,\n",
       " 'aupr_entropy_impulse_noise_3': 0.8593557295375434,\n",
       " 'avg_acc_1': 0.8668661917892156,\n",
       " 'avg_acc_2': 0.0,\n",
       " 'avg_acc_3': 0.743895143995098,\n",
       " 'avg_acc_4': 0.0,\n",
       " 'avg_acc_5': 0.5558448223039216,\n",
       " 'avg_auroc_ent_1': 0.6105627653333333,\n",
       " 'avg_auroc_ent_2': 0.0,\n",
       " 'avg_auroc_ent_3': 0.7225363843333332,\n",
       " 'avg_auroc_ent_4': 0.0,\n",
       " 'avg_auroc_ent_5': 0.8307607386666668,\n",
       " 'avg_aupr_ent_1': 0.5954455739489379,\n",
       " 'avg_aupr_ent_2': 0.0,\n",
       " 'avg_aupr_ent_3': 0.6994977993828484,\n",
       " 'avg_aupr_ent_4': 0.0,\n",
       " 'avg_aupr_ent_5': 0.8050712807231013,\n",
       " 'avg_auroc_1': 0.6089675930000001,\n",
       " 'avg_auroc_2': 0.0,\n",
       " 'avg_auroc_3': 0.7193561329999999,\n",
       " 'avg_auroc_4': 0.0,\n",
       " 'avg_auroc_5': 0.8254308016666666,\n",
       " 'avg_aupr_1': 0.6063896367093409,\n",
       " 'avg_aupr_2': 0.0,\n",
       " 'avg_aupr_3': 0.7238452920391159,\n",
       " 'avg_aupr_4': 0.0,\n",
       " 'avg_aupr_5': 0.8377701577617408,\n",
       " 'avg_entropy_1': 0.21594958212128243,\n",
       " 'avg_entropy_2': 0.0,\n",
       " 'avg_entropy_3': 0.3632364570013907,\n",
       " 'avg_entropy_4': 0.0,\n",
       " 'avg_entropy_5': 0.5676386029088785}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
