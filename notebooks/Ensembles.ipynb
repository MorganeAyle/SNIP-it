{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/nfs/homedirs/ayle/guided-research/SNIP-it/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import foolbox as fb\n",
    "from experiments.main import load_checkpoint\n",
    "from models import GeneralModel\n",
    "from models.statistics.Metrics import Metrics\n",
    "from utils.config_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.system_utils import *\n",
    "from utils.attacks_utils import get_attack\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arguments = dict({\n",
    "'eval_freq': 1000,  # evaluate every n batches\n",
    "    'save_freq': 1e6,  # save model every n epochs, besides before and after training\n",
    "    'batch_size': 64,  # size of batches, for Imagenette 128\n",
    "    'seed': 1234,  # random seed\n",
    "    'max_training_minutes': 6120 , # one hour and a 45 minutes max, process killed after n minutes (after finish of epoch)\n",
    "    'plot_weights_freq': 50, # plot pictures to tensorboard every n epochs\n",
    "    'prune_freq': 1, # if pruning during training: how long to wait before starting\n",
    "    'prune_delay': 0, # \"if pruning during training: 't' from algorithm box, interval between pruning events, default=0\n",
    "    'prune_to': 10,\n",
    "    'epochs': 20,\n",
    "    'rewind_to': 0, # rewind to this epoch if rewinding is done\n",
    "    'snip_steps': 5, # 's' in algorithm box, number of pruning steps for 'rule of thumb', TODO\n",
    "    'pruning_rate': 0.0 , # pruning rate passed to criterion at pruning event. however, most override this\n",
    "    'growing_rate': 0.0000 , # grow back so much every epoch (for future criterions)\n",
    "    'pruning_limit': 0.00,  # Prune until here, if structured in nodes, if unstructured in weights. most criterions use this instead of the pruning_rate\n",
    "    'learning_rate': 2e-3,\n",
    "    'grad_clip': 10,\n",
    "    'grad_noise': 0 , # added gaussian noise to gradients\n",
    "    'l2_reg': 5e-5 , # weight decay\n",
    "    'l1_reg': 0 , # l1-norm regularisation\n",
    "    'lp_reg': 0 , # lp regularisation with p < 1\n",
    "    'l0_reg': 1.0 , # l0 reg lambda hyperparam\n",
    "    'hoyer_reg': 0.001 , # hoyer reg lambda hyperparam\n",
    "    'beta_ema': 0.999 , # l0 reg beta ema hyperparam\n",
    "\n",
    "    'loss': 'CrossEntropy',\n",
    "    'optimizer': 'ADAM',\n",
    "    'model': 'ResNet18',  # ResNet not supported with structured\n",
    "    'data_set': 'CIFAR10',\n",
    "    'ood_data_set': 'SVHN',\n",
    "    'prune_criterion': 'EmptyCrit',  # options: SNIP, SNIPit, SNIPitDuring, UnstructuredRandom, GRASP, HoyerSquare, IMP, // SNAPit, StructuredRandom, GateDecorators, EfficientConvNets, GroupHoyerSquare\n",
    "    'train_scheme': 'DefaultTrainer' , # default: DefaultTrainer\n",
    "    'attack': 'FGSM',\n",
    "    'epsilon': 6,\n",
    "    'eval_ood_data_sets': ['SVHN', 'CIFAR100', 'GAUSSIAN', 'OODOMAIN'],\n",
    "    'eval_attacks': ['FGSM', 'L2FGSM'],\n",
    "    'eval_epsilons': [4, 6, 12, 24, 48],\n",
    "\n",
    "    'device': 'cuda',\n",
    "    'results_dir': \"tests\",\n",
    "\n",
    "    'checkpoint_name': '2021-05-30_19.59.39_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPitDuring_pruning-limit=0.98_prune-freq=4_prune-delay=8_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=1234',\n",
    "    'checkpoint_model': 'ResNet18_finished',\n",
    "\n",
    "    'disable_cuda_benchmark': 1 , # speedup (disable) vs reproducibility (leave it)\n",
    "    'eval': 0,\n",
    "    'disable_autoconfig': 0 , # for the brave\n",
    "    'preload_all_data': 0 , # load all data into ram memory for speedups\n",
    "    'tuning': 0 , # splits trainset into train and validationset, omits test set\n",
    "\n",
    "    'track_weights': 0 , # \"keep statistics on the weights through training\n",
    "    'disable_masking': 1 , # disable the ability to prune unstructured\n",
    "    'enable_rewinding': 0 , # enable the ability to rewind to previous weights\n",
    "    'outer_layer_pruning': 1, # allow to prune outer layers (unstructured) or not (structured)\n",
    "    'first_layer_dense': 0,\n",
    "    'random_shuffle_labels': 0  ,# run with random-label experiment from zhang et al\n",
    "    'l0': 0,  # run with l0 criterion, might overwrite some other arguments\n",
    "    'hoyer_square': 0, # \"run in unstructured DeephoyerSquare criterion, might overwrite some other arguments\n",
    "    'group_hoyer_square': 0 ,# run in unstructured Group-DeephoyerSquare criterion, might overwrite some other arguments\n",
    "\n",
    "    'disable_histograms': 0,\n",
    "    'disable_saliency': 0,\n",
    "    'disable_confusion': 0,\n",
    "    'disable_weightplot': 0,\n",
    "    'disable_netplot': 0,\n",
    "    'skip_first_plot': 0,\n",
    "    'disable_activations': 0,\n",
    "    \n",
    "#    'input_dim': [1, 28, 28],\n",
    "#    'output_dim': 10,\n",
    "#    'hidden_dim': [512],\n",
    "#    'N': 60000,\n",
    "    \n",
    "    'input_dim': [3, 32, 32],\n",
    "      'output_dim': 10,\n",
    "      'hidden_dim': [512],\n",
    "      'N': 60000\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = Metrics()\n",
    "out = metrics.log_line\n",
    "metrics._batch_size = arguments['batch_size']\n",
    "metrics._eval_freq = arguments['eval_freq']\n",
    "set_results_dir(arguments[\"results_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model: GeneralModel = find_right_model(\n",
    "        NETWORKS_DIR, arguments['model'],\n",
    "        device=arguments['device'],\n",
    "        hidden_dim=arguments['hidden_dim'],\n",
    "        input_dim=arguments['input_dim'],\n",
    "        output_dim=arguments['output_dim'],\n",
    "        is_maskable=arguments['disable_masking'],\n",
    "        is_tracking_weights=arguments['track_weights'],\n",
    "        is_rewindable=arguments['enable_rewinding'],\n",
    "        is_growable=arguments['growing_rate'] > 0,\n",
    "        outer_layer_pruning=arguments['outer_layer_pruning'],\n",
    "        maintain_outer_mask_anyway=(\n",
    "                                       not arguments['outer_layer_pruning']) and (\n",
    "                                           \"Structured\" in arguments['prune_criterion']),\n",
    "        l0=arguments['l0'],\n",
    "        l0_reg=arguments['l0_reg'],\n",
    "        N=arguments['N'],\n",
    "        beta_ema=arguments['beta_ema'],\n",
    "        l2_reg=arguments['l2_reg']\n",
    ").to(arguments['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path, model, out):\n",
    "    state = DATA_MANAGER.load_python_obj(path)\n",
    "    try:\n",
    "        model.load_state_dict(state)\n",
    "    except KeyError as e:\n",
    "        print(list(state.keys()))\n",
    "        raise e\n",
    "    out(f\"Loaded checkpoint {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, out):\n",
    "    with open(path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    out(f\"Loaded checkpoint {path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/VGG16/2021-06-02_21.28.54_model=VGG16_dataset=CIFAR10_prune-criterion=StructuredEFGit_pruning-limit=0.9_prune-freq=1_prune-delay=0_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=3456/models/VGG16_mod_finished.pickle'\n",
    "path2 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/VGG16/2021-06-02_21.28.55_model=VGG16_dataset=CIFAR10_prune-criterion=StructuredEFGit_pruning-limit=0.9_prune-freq=1_prune-delay=0_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=2345/models/VGG16_mod_finished.pickle'\n",
    "path3 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/VGG16/2021-06-02_21.28.56_model=VGG16_dataset=CIFAR10_prune-criterion=StructuredEFGit_pruning-limit=0.9_prune-freq=1_prune-delay=0_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=1234/models/VGG16_mod_finished.pickle'\n",
    "path4 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/VGG16/2021-06-02_21.48.55_model=VGG16_dataset=CIFAR10_prune-criterion=StructuredEFGit_pruning-limit=0.9_prune-freq=1_prune-delay=0_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=4567/models/VGG16_mod_finished.pickle'\n",
    "path5 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/VGG16/2021-06-02_22.32.42_model=VGG16_dataset=CIFAR10_prune-criterion=StructuredEFGit_pruning-limit=0.9_prune-freq=1_prune-delay=0_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=5678/models/VGG16_mod_finished.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(path1, out)\n",
    "model2 = load_model(path2, out)\n",
    "model3 = load_model(path3, out)\n",
    "model4 = load_model(path4, out)\n",
    "model5 = load_model(path5, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-05-30_16.14.35_model=ResNet18_dataset=CIFAR10_ood-dataset=SVHN_attack=FGSM_epsilon=4_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_rewind-to=0_train-scheme=DefaultTrainer_seed=1234/models/ResNet18_finished'\n",
    "#path1 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-05-30_21.19.53_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.98_prune-freq=4_prune-delay=8_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=1234/models/ResNet18_finished'\n",
    "# path1 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-05-30_20.36.55_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.8_prune-freq=4_prune-delay=8_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=1234/models/ResNet18_finished'\n",
    "# path1 = '/nfs/students/ayle/guided-research/results/VGG16/2021-05-31_00.45.30_model=VGG16_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.93_prune-freq=4_prune-delay=8_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=1234/models/VGG16_finished'\n",
    "model1 = deepcopy(model) \n",
    "load_checkpoint(path1, model1, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-05-31_16.23.52_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=2345/models/ResNet18_finished'\n",
    "#path2 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-06-01_00.40.07_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.98_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=2345/models/ResNet18_finished'\n",
    "# path2 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-06-01_00.40.07_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.8_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=2345/models/ResNet18_finished'\n",
    "# path2 = '/nfs/students/ayle/guided-research/results/VGG16/2021-05-31_01.03.02_model=VGG16_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.93_prune-freq=4_prune-delay=8_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=2345/models/VGG16_finished'\n",
    "model2 = deepcopy(model) \n",
    "load_checkpoint(path2, model2, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path3 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-05-31_16.23.51_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=3456/models/ResNet18_finished'\n",
    "#path3 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-06-01_02.14.47_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.98_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=3456/models/ResNet18_finished'\n",
    "# path3 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-06-01_01.02.17_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.8_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=3456/models/ResNet18_finished'\n",
    "# path3 = '/nfs/students/ayle/guided-research/results/VGG16/2021-05-31_02.18.47_model=VGG16_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.93_prune-freq=4_prune-delay=8_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=3456/models/VGG16_finished'\n",
    "model3 = deepcopy(model) \n",
    "load_checkpoint(path3, model3, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path4 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-05-31_16.23.49_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=4567/models/ResNet18_finished'\n",
    "#path4 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-06-01_03.04.38_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.98_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=4567/models/ResNet18_finished'\n",
    "# path4 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-06-01_02.23.39_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.8_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=4567/models/ResNet18_finished'\n",
    "# path4 = '/nfs/students/ayle/guided-research/results/VGG16/2021-05-31_02.56.03_model=VGG16_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.93_prune-freq=4_prune-delay=8_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=4567/models/VGG16_finished'\n",
    "model4 = deepcopy(model) \n",
    "load_checkpoint(path4, model4, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path5 = '/nfs/students/ayle/guided-research/results/ResNet18/2021-05-31_16.23.50_model=ResNet18_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.0_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=5678/models/ResNet18_finished'\n",
    "#path5 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-06-01_16.37.04_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.98_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=5678/models/ResNet18_finished'\n",
    "# path5 = '/nfs/homedirs/ayle/guided-research/SNIP-it/gitignored/results/ResNet18/2021-06-01_15.27.48_model=ResNet18_dataset=CIFAR10_prune-criterion=EarlyJohn_pruning-limit=0.8_prune-freq=1_prune-delay=0_outer-layer-pruning=1_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=5678/models/ResNet18_finished'\n",
    "# path5 = '/nfs/students/ayle/guided-research/results/VGG16/2021-05-31_03.46.55_model=VGG16_dataset=CIFAR10_prune-criterion=EmptyCrit_pruning-limit=0.93_prune-freq=4_prune-delay=8_outer-layer-pruning=0_prune-to=5_rewind-to=0_train-scheme=DefaultTrainer_seed=5678/models/VGG16_finished'\n",
    "model5 = deepcopy(model) \n",
    "load_checkpoint(path5, model5, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = arguments['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_loader, test_loader = find_right_model(\n",
    "    DATASETS, arguments['data_set'],\n",
    "    arguments=arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OOD data\n",
    "_, ood_loader = find_right_model(\n",
    "    DATASETS, arguments['ood_data_set'],\n",
    "    arguments=arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "model5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def calculate_auroc(correct, predictions):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(correct, predictions)\n",
    "    auroc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr)\n",
    "    return auroc\n",
    "\n",
    "\n",
    "def calculate_aupr(correct, predictions):\n",
    "    aupr = metrics.average_precision_score(correct, predictions)\n",
    "    return aupr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ood_labels = []\n",
    "ood_scores = []\n",
    "\n",
    "mean_var = 0\n",
    "count = 0\n",
    "\n",
    "accuracy = 0\n",
    "total_disagreement = 0\n",
    "total_time = 0\n",
    "\n",
    "kl_loss = torch.nn.KLDivLoss(reduction='none')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        preds = torch.zeros((5, len(data), 10))\n",
    "        disagreement = torch.zeros((5, len(data)))\n",
    "        count += 1\n",
    "        t = 0\n",
    "        \n",
    "        data = data.to(device)\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model1(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[0] = probs.cpu()\n",
    "        \n",
    "#         breakpoint()\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model2(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[1] = probs.cpu()\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model3(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[2] = probs.cpu()\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model4(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[3] = probs.cpu()\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model5(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[4] = probs.cpu()\n",
    "        \n",
    "        all_probs = preds.mean(0)\n",
    "                                        \n",
    "        disagreement[0] = kl_loss(torch.log(preds[0]), all_probs.cpu()).sum(-1)\n",
    "        disagreement[1] = kl_loss(torch.log(preds[1]), all_probs.cpu()).sum(-1)\n",
    "        disagreement[2] = kl_loss(torch.log(preds[2]), all_probs.cpu()).sum(-1)\n",
    "        disagreement[3] = kl_loss(torch.log(preds[3]), all_probs.cpu()).sum(-1)\n",
    "        disagreement[4] = kl_loss(torch.log(preds[4]), all_probs.cpu()).sum(-1)\n",
    "\n",
    "        max_probs, max_indices  = all_probs.max(1)\n",
    "        max_probs = max_probs.detach().cpu().numpy()\n",
    "                \n",
    "        ood_labels.append(np.ones_like(max_probs))\n",
    "        ood_scores.append(max_probs)\n",
    "        \n",
    "#         ood_labels.append(np.zeros_like(disagreement.mean(0)))\n",
    "#         ood_scores.append(disagreement.mean(0))\n",
    "        \n",
    "        total_time += t\n",
    "        \n",
    "        accuracy += (labels == max_indices.cpu()).float().mean()        \n",
    "        mean_var += torch.var(preds, dim=0).mean()\n",
    "        \n",
    "print(mean_var / count)\n",
    "print(accuracy / count)\n",
    "print(total_time / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_var = 0\n",
    "count = 0\n",
    "\n",
    "kl_loss = torch.nn.KLDivLoss(reduction='none')\n",
    "total_time = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in ood_loader:\n",
    "        preds = torch.zeros((5, len(data), 10))\n",
    "        disagreement = torch.zeros((5, len(data)))\n",
    "        count += 1\n",
    "        t = 0\n",
    "        \n",
    "        data = data.to(device)\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model1(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[0] = probs.cpu()\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model2(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[1] = probs.cpu()\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model3(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[2] = probs.cpu()\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model4(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[3] = probs.cpu()\n",
    "        \n",
    "        start = time.time()\n",
    "        out = model5(data)\n",
    "        t += time.time() - start\n",
    "        probs = F.softmax(out, 1)\n",
    "        preds[4] = probs.cpu()\n",
    "        \n",
    "        all_probs = preds.mean(0)\n",
    "                                        \n",
    "        disagreement[0] = kl_loss(torch.log(preds[0]), all_probs.cpu()).sum(-1)\n",
    "        disagreement[1] = kl_loss(torch.log(preds[1]), all_probs.cpu()).sum(-1)\n",
    "        disagreement[2] = kl_loss(torch.log(preds[2]), all_probs.cpu()).sum(-1)\n",
    "        disagreement[3] = kl_loss(torch.log(preds[3]), all_probs.cpu()).sum(-1)\n",
    "        disagreement[4] = kl_loss(torch.log(preds[4]), all_probs.cpu()).sum(-1)\n",
    "\n",
    "        max_probs, max_indices  = all_probs.max(1)\n",
    "        max_probs = max_probs.detach().cpu().numpy()\n",
    "                \n",
    "        ood_labels.append(np.zeros_like(max_probs))\n",
    "        ood_scores.append(max_probs)\n",
    "        \n",
    "#         ood_labels.append(np.ones_like(disagreement.mean(0)))\n",
    "#         ood_scores.append(disagreement.mean(0))\n",
    "        \n",
    "        total_time += t\n",
    "        \n",
    "        mean_var += torch.var(preds, dim=0).mean()\n",
    "        \n",
    "print(mean_var / count)\n",
    "print(total_time / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(ood_scores)[:10000].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(ood_scores)[10000:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_auroc(np.concatenate(ood_labels), np.concatenate(ood_scores)))\n",
    "print(calculate_aupr(np.concatenate(ood_labels), np.concatenate(ood_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.mean = [0.485, 0.456, 0.406]  # avg 0.449\n",
    "        self.std = [0.229, 0.224, 0.225]  # avg 0.226\n",
    "        self.transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=self.mean, std=self.std)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = self.images[item] / 255\n",
    "        image = self.transforms(image.transpose((1, 2, 0)))\n",
    "        return image.to(torch.float32), torch.tensor(self.labels[item], dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    if arguments[\"data_set\"] == \"CIFAR10\":\n",
    "        ds_path = os.path.join(DATASET_PATH, \"cifar10_corrupted\")\n",
    "        for ds_dataset_name in os.listdir(ds_path):\n",
    "            print(ds_dataset_name)\n",
    "            npz_dataset = np.load(os.path.join(ds_path, ds_dataset_name))\n",
    "\n",
    "            ds_dataset = DS(npz_dataset[\"images\"], npz_dataset[\"labels\"])\n",
    "            ds_loader = torch.utils.data.DataLoader(\n",
    "                ds_dataset,\n",
    "                batch_size=arguments['batch_size'],\n",
    "                shuffle=False,\n",
    "                pin_memory=True,\n",
    "                num_workers=4\n",
    "            )\n",
    "            \n",
    "            mean_var = 0\n",
    "            count = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            for data, labels in ds_loader:\n",
    "                preds = torch.zeros((5, len(data), 10))\n",
    "                count += 1\n",
    "\n",
    "                data = data.to(device)\n",
    "                all_probs = 0\n",
    "\n",
    "                out = model1(data)\n",
    "                probs = F.softmax(out, 1)\n",
    "                all_probs += probs\n",
    "                preds[0] = probs.cpu()\n",
    "\n",
    "                out = model2(data)\n",
    "                probs = F.softmax(out, 1)\n",
    "                all_probs += probs\n",
    "                preds[1] = probs.cpu()\n",
    "\n",
    "                out = model3(data)\n",
    "                probs = F.softmax(out, 1)\n",
    "                all_probs += probs\n",
    "                preds[2] = probs.cpu()\n",
    "\n",
    "                out = model4(data)\n",
    "                probs = F.softmax(out, 1)\n",
    "                all_probs += probs\n",
    "                preds[3] = probs.cpu()\n",
    "\n",
    "                out = model5(data)\n",
    "                probs = F.softmax(out, 1)\n",
    "                all_probs += probs\n",
    "                preds[4] = probs.cpu()\n",
    "\n",
    "                all_probs = all_probs / 5\n",
    "\n",
    "                max_probs, max_indices  = all_probs.max(1)\n",
    "                max_probs = max_probs.detach().cpu().numpy()\n",
    "                ood_labels.append(np.zeros_like(max_probs))\n",
    "                ood_scores.append(max_probs)\n",
    "\n",
    "                mean_var += torch.var(preds, dim=0).mean()\n",
    "                accuracy += (labels == max_indices.cpu()).float().mean()   \n",
    "\n",
    "            print(mean_var / count)\n",
    "            print(accuracy / count)\n",
    "            print(calculate_auroc(np.concatenate(ood_labels), np.concatenate(ood_scores)))\n",
    "            print(calculate_aupr(np.concatenate(ood_labels), np.concatenate(ood_scores)))\n",
    "            \n",
    "            breakpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attack in arguments['eval_attacks']:\n",
    "    for epsilon in arguments['eval_epsilons']:\n",
    "        out(\"Attack {}\".format(attack))\n",
    "        # build tester\n",
    "        tester = find_right_model(\n",
    "            TESTERS_DIR, 'AdversarialEvaluation',\n",
    "            attack=attack,\n",
    "#             model=trainer._model,\n",
    "            model = model,\n",
    "            device=device,\n",
    "            arguments=None,\n",
    "            test_loader=test_loader,\n",
    "        )\n",
    "\n",
    "        out(\"Epsilon {}\".format(str(epsilon)))\n",
    "        res = tester.evaluate(epsilon=epsilon)\n",
    "\n",
    "        for key, value in res.items():\n",
    "            results[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for ood_data_set in arguments['eval_ood_data_sets']:\n",
    "        out(\"OOD Dataset: {}\".format(ood_data_set))\n",
    "        # load data\n",
    "        _, test_loader = find_right_model(\n",
    "            DATASETS, arguments['data_set'],\n",
    "            arguments=arguments\n",
    "        )\n",
    "\n",
    "        # load OOD data\n",
    "        _, ood_loader = find_right_model(\n",
    "            DATASETS, ood_data_set,\n",
    "            arguments=arguments\n",
    "        )\n",
    "        # build tester\n",
    "        tester = find_right_model(\n",
    "            TESTERS_DIR, 'OODEvaluation',\n",
    "#             model=trainer._model,\n",
    "            model = model,\n",
    "            device=device,\n",
    "            arguments=None,\n",
    "            test_loader=test_loader,\n",
    "            ood_loader=ood_loader,\n",
    "            ood_dataset=ood_data_set\n",
    "        )\n",
    "        res = tester.evaluate()\n",
    "\n",
    "        for key, value in res.items():\n",
    "            results[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    if arguments[\"data_set\"] == \"CIFAR10\":\n",
    "        ds_path = os.path.join(DATASET_PATH, \"cifar10_corrupted\")\n",
    "        for ds_dataset_name in os.listdir(ds_path):\n",
    "            npz_dataset = np.load(os.path.join(ds_path, ds_dataset_name))\n",
    "\n",
    "            ds_dataset = DS(npz_dataset[\"images\"], npz_dataset[\"labels\"])\n",
    "            ds_loader = torch.utils.data.DataLoader(\n",
    "                ds_dataset,\n",
    "                batch_size=arguments['batch_size'],\n",
    "                shuffle=False,\n",
    "                pin_memory=True,\n",
    "                num_workers=4\n",
    "            )\n",
    "\n",
    "            # build tester\n",
    "            tester = find_right_model(\n",
    "                TESTERS_DIR, 'DSEvaluation',\n",
    "                model=trainer._model,\n",
    "                device=device,\n",
    "                arguments=None,\n",
    "                test_loader=test_loader,\n",
    "                ds_loader=ds_loader,\n",
    "                ds_dataset=ds_dataset_name.split('.')[0]\n",
    "            )\n",
    "            res = tester.evaluate()\n",
    "\n",
    "            for key, value in res.items():\n",
    "                results[key] = value\n",
    "\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
