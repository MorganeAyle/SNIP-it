{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/nfs/homedirs/ayle/guided-research/SNIP-it/glow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train.py /nfs/students/ayle/guided-research/FASHION-jpg/training --img_size 32 --channels 3 --batch 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from math import log, sqrt, pi\n",
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from model import Glow\n",
    "from glow.Johnit import Johnit\n",
    "from glow.StructuredEFGit import StructuredEFGit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch = 16\n",
    "n_flow = 32\n",
    "n_block = 4\n",
    "no_lu = False\n",
    "affine = False\n",
    "n_bits = 5\n",
    "lr = 1e-5\n",
    "img_size = 32\n",
    "channels = 3\n",
    "temp = 0.7\n",
    "n_sample = 20\n",
    "iterations = 1000\n",
    "\n",
    "pruning_limit = 0.5\n",
    "local_pruning = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(path, batch_size, image_size):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = datasets.ImageFolder(path, transform=transform)\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=4)\n",
    "    loader = iter(loader)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(loader)\n",
    "\n",
    "        except StopIteration:\n",
    "            loader = DataLoader(\n",
    "                dataset, shuffle=True, batch_size=batch_size, num_workers=4\n",
    "            )\n",
    "            loader = iter(loader)\n",
    "            yield next(loader)\n",
    "\n",
    "\n",
    "def calc_z_shapes(n_channel, input_size, n_flow, n_block):\n",
    "    z_shapes = []\n",
    "\n",
    "    for i in range(n_block - 1):\n",
    "        input_size //= 2\n",
    "        n_channel *= 2\n",
    "\n",
    "        z_shapes.append((n_channel, input_size, input_size))\n",
    "\n",
    "    input_size //= 2\n",
    "    z_shapes.append((n_channel * 4, input_size, input_size))\n",
    "\n",
    "    return z_shapes\n",
    "\n",
    "\n",
    "def calc_loss(log_p, logdet, image_size, n_bins, channels):\n",
    "    # log_p = calc_log_p([z_list])\n",
    "    n_pixel = image_size * image_size * channels\n",
    "\n",
    "    loss = -log(n_bins) * n_pixel\n",
    "    loss = loss + logdet + log_p\n",
    "\n",
    "    return (\n",
    "        (-loss / (log(2) * n_pixel)).mean(),\n",
    "        (log_p / (log(2) * n_pixel)).mean(),\n",
    "        (logdet / (log(2) * n_pixel)).mean(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single = Glow(\n",
    "    channels, n_flow, n_block, affine=affine, conv_lu=not no_lu\n",
    ")\n",
    "model = nn.DataParallel(model_single)\n",
    "model = model.to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"checkpoint/model_criterion=Johnit_sparsity=0.9_local=True.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/nfs/students/ayle/guided-research/FASHION-jpg/training\"\n",
    "path  =\"/nfs/students/ayle/guided-research/CIFAR-10-images/train\"\n",
    "dataset = iter(sample_data(path, batch, img_size))\n",
    "n_bins = 2.0 ** n_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = Johnit(limit=pruning_limit, model=model.module, generative=True, nbins=n_bins, img_size=img_size, channels=channels, loss_f=calc_loss)\n",
    "# criterion.prune(pruning_limit, train_loader=sample_data(path, batch, img_size), local=local_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = StructuredEFGit(limit=pruning_limit, model=model.module, generative=True, nbins=n_bins, img_size=img_size, channels=channels, loss_f=calc_loss)\n",
    "# criterion.prune(pruning_limit, train_loader=sample_data(path, batch, img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sample = []\n",
    "z_shapes = calc_z_shapes(channels, img_size, n_flow, n_block)\n",
    "for z in z_shapes:\n",
    "    z_new = torch.randn(n_sample, *z) * temp\n",
    "    z_sample.append(z_new.to(device))\n",
    "\n",
    "with tqdm(range(iterations)) as pbar:\n",
    "    for i in pbar:\n",
    "        image, _ = next(dataset)\n",
    "        image = image.to(device)\n",
    "\n",
    "        image = image * 255\n",
    "        \n",
    "        if n_bits < 8:\n",
    "            image = torch.floor(image / 2 ** (8 - n_bits))\n",
    "\n",
    "        image = image / n_bins - 0.5\n",
    "\n",
    "        model.module.apply_weight_mask()\n",
    "\n",
    "        if i == 0:\n",
    "            with torch.no_grad():\n",
    "                log_p, logdet, _ = model.module(\n",
    "                    image + torch.rand_like(image) / n_bins\n",
    "                )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                utils.save_image(\n",
    "                    model_single.reverse(z_sample).cpu().data,\n",
    "                    f\"sample/{str(i + 1).zfill(6)}.png\",\n",
    "                    normalize=True,\n",
    "                    nrow=10,\n",
    "                    range=(-0.5, 0.5),\n",
    "                    )\n",
    "                \n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            log_p, logdet, _ = model(image + torch.rand_like(image) / n_bins)\n",
    "\n",
    "        logdet = logdet.mean()\n",
    "\n",
    "        loss, log_p, log_det = calc_loss(log_p, logdet, img_size, n_bins, channels=channels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        # warmup_lr = args.lr * min(1, i * batch_size / (50000 * 10))\n",
    "        warmup_lr = lr\n",
    "        optimizer.param_groups[0][\"lr\"] = warmup_lr\n",
    "        optimizer.step()\n",
    "\n",
    "        model.module.apply_weight_mask()\n",
    "\n",
    "        pbar.set_description(\n",
    "            f\"Loss: {loss.item():.5f}; logP: {log_p.item():.5f}; logdet: {log_det.item():.5f}; lr: {warmup_lr:.7f}\"\n",
    "        )\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                utils.save_image(\n",
    "                    model_single.reverse(z_sample).cpu().data,\n",
    "                    f\"sample/{str(i + 1).zfill(6)}.png\",\n",
    "                    normalize=True,\n",
    "                    nrow=10,\n",
    "                    range=(-0.5, 0.5),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### EVALUATION\n",
    "\n",
    "\n",
    "path = \"/nfs/students/ayle/guided-research/FASHION-jpg/testing\"\n",
    "dataset = iter(sample_data(path, batch, img_size))\n",
    "n_bins = 2.0 ** n_bits\n",
    "\n",
    "z_sample = []\n",
    "z_shapes = calc_z_shapes(channels, img_size, n_flow, n_block)\n",
    "for z in z_shapes:\n",
    "    z_new = torch.randn(n_sample, *z) * temp\n",
    "    z_sample.append(z_new.to(device))\n",
    "    \n",
    "cum_log_p = []\n",
    "\n",
    "with tqdm(range(int(10000 / batch))) as pbar:\n",
    "    for i in pbar:\n",
    "        image, _ = next(dataset)\n",
    "        image = image.to(device)\n",
    "\n",
    "        image = image * 255\n",
    "\n",
    "        if n_bits < 8:\n",
    "            image = torch.floor(image / 2 ** (8 - n_bits))\n",
    "\n",
    "        image = image / n_bins - 0.5\n",
    "\n",
    "        if i == 0:\n",
    "            with torch.no_grad():\n",
    "                log_p, logdet, _ = model.module(\n",
    "                    image\n",
    "                )\n",
    "                cum_log_p.append(log_p.cpu().detach().numpy())\n",
    "\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            log_p, logdet, _ = model(image)\n",
    "            cum_log_p.append(log_p.cpu().detach().numpy())\n",
    "\n",
    "        logdet = logdet.mean()\n",
    "\n",
    "        loss, log_p, log_det = calc_loss(log_p, logdet, img_size, n_bins, channels=channels)\n",
    "\n",
    "        pbar.set_description(\n",
    "            f\"Loss: {loss.item():.5f}; logP: {log_p.item():.5f}; Avg logP: {np.mean(cum_log_p).item():.5f}; logdet: {log_det.item():.5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### EVALUATION\n",
    "\n",
    "\n",
    "path = \"/nfs/students/ayle/guided-research/MNIST-jpg/testing\"\n",
    "dataset = iter(sample_data(path, batch, img_size))\n",
    "n_bins = 2.0 ** n_bits\n",
    "\n",
    "z_sample = []\n",
    "z_shapes = calc_z_shapes(channels, img_size, n_flow, n_block)\n",
    "for z in z_shapes:\n",
    "    z_new = torch.randn(n_sample, *z) * temp\n",
    "    z_sample.append(z_new.to(device))\n",
    "    \n",
    "ood_cum_log_p = []\n",
    "\n",
    "with tqdm(range(int(10000 / batch))) as pbar:\n",
    "    for i in pbar:\n",
    "        image, _ = next(dataset)\n",
    "        image = image.to(device)\n",
    "\n",
    "        image = image * 255\n",
    "\n",
    "        if n_bits < 8:\n",
    "            image = torch.floor(image / 2 ** (8 - n_bits))\n",
    "\n",
    "        image = image / n_bins - 0.5\n",
    "\n",
    "        if i == 0:\n",
    "            with torch.no_grad():\n",
    "                log_p, logdet, _ = model.module(\n",
    "                    image\n",
    "                )\n",
    "                ood_cum_log_p.append(log_p.cpu().detach().numpy())\n",
    "\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            log_p, logdet, _ = model(image)\n",
    "            ood_cum_log_p.append(log_p.cpu().detach().numpy())\n",
    "\n",
    "        logdet = logdet.mean()\n",
    "\n",
    "        loss, log_p, log_det = calc_loss(log_p, logdet, img_size, n_bins, channels=channels)\n",
    "\n",
    "        pbar.set_description(\n",
    "            f\"Loss: {loss.item():.5f}; logP: {log_p.item():.5f}; Avg logP: {np.mean(ood_cum_log_p).item():.5f}; logdet: {log_det.item():.5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_log_p = np.concatenate([x for x in cum_log_p])\n",
    "ood_cum_log_p = np.concatenate([x for x in ood_cum_log_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(cum_log_p, density=True, bins=100, histtype='stepfilled', label='FASHION', alpha=0.7)\n",
    "plt.hist(ood_cum_log_p, density=True, bins=100, histtype='stepfilled', label='MNIST', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
